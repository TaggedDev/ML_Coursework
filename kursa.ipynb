{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32624065-f019-4d76-9df4-6ec004c53d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f58544eb-3f66-4820-aed6-15ee334c49b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a7a014-68f7-43a5-89a5-24b15bf9c1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Audio, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf0d56a0-5eb7-4a78-82a2-d939dd22867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk, rename\n",
    "from os.path import join, exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7994ef5-eb5c-42a4-a522-640c422a2a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import soundfile as sf\n",
    "\n",
    "from Levenshtein import distance\n",
    "from random import choice\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59599353-89ca-48c2-8677-a0767a988156",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332f387f-dd79-40ef-9a9e-dc3efb71781c",
   "metadata": {},
   "source": [
    "При подготовке к выполнению курсовой работы я наткнулся на github репозиторий https://github.com/snakers4/open_stt - открытые speech to text датасеты, распространяющиеся по лицензии CC-BY-NC (то есть бесплатные для обучения). \n",
    "\n",
    "Среди всего объема данных более 300 Гб я выбрал раздел asr_public_stories_1 объемом 4 Гб. В нем диктор читает текст сказок (аудиокниги). Аудиоданные хранятся в файлах с расширением .opus, а их текстовая расшифровка хранится в файле с таким же названием с расширением .txt. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1092f312-c08f-44ea-9d42-86c09749bb61",
   "metadata": {},
   "source": [
    "Для правильной загрузки датасета нужно сделать файл metadata.csv, который бы содержал информацию о аудиофайле и его настоящем содержимом. Спарсим данные из папки с помощью модуля `os`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f3528aab-3c19-4670-aa49-4268c2d46e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _walk at 0x00000264A2FEAB60>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_folder = r'C:\\Users\\Denis\\Desktop\\Kursach\\Data\\asr_public_stories_1'\n",
    "walk_generator = walk(root_folder)\n",
    "walk_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "74f87383-bd3e-48f0-ba70-aadeab8a6a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = []\n",
    "text_files = []\n",
    "for root, dirs, files in walk_generator:\n",
    "    for filename in files:\n",
    "        if '.opus' in filename:\n",
    "            path = join(root, filename)\n",
    "            audio_files.append(path)\n",
    "            text_files.append(path.replace('.opus', '.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "74381246-1d31-4d12-8e3c-b7d219b4a894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46138, 46138)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio_files), len(text_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03de5e48-d1cd-49d9-a1a4-09d09610df79",
   "metadata": {},
   "source": [
    "Видим, что датасет содержит в себе более 46 тысяч аудиозаписей и текстовые расшифровки к ним"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cdf2988e-454e-4b6a-bd06-86bdfb93a7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = ['\\\\'.join(path.split('\\\\')[-3:]) for path in audio_files]\n",
    "text_files = ['\\\\'.join(path.split('\\\\')[-3:]) for path in text_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "09745a84-a7a2-4c79-8c35-611a6a4270d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['0\\\\00\\\\4242dbd680d3.opus',\n",
       "  '0\\\\00\\\\42cf17b45995.opus',\n",
       "  '0\\\\00\\\\495bfc4a6f79.opus',\n",
       "  '0\\\\00\\\\7acc40962b1b.opus',\n",
       "  '0\\\\00\\\\8ffb80f141ae.opus'],\n",
       " ['0\\\\00\\\\4242dbd680d3.txt',\n",
       "  '0\\\\00\\\\42cf17b45995.txt',\n",
       "  '0\\\\00\\\\495bfc4a6f79.txt',\n",
       "  '0\\\\00\\\\7acc40962b1b.txt',\n",
       "  '0\\\\00\\\\8ffb80f141ae.txt'])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_files[:5], text_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d2bae1-2f2b-4f5e-af3a-2177cbb0d70d",
   "metadata": {},
   "source": [
    "Теперь воспользуемся обычным методом read() для прочтения всех файлов. Сохраним полученный текст, обработаем вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c38d2102-bec5-4c1d-afd7-856c69e666c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['совершенная технология\\n',\n",
       " 'день слышался ей\\n',\n",
       " 'что яна обложки сборников сказок\\n',\n",
       " 'мышиный чепухи и\\n',\n",
       " 'пересмотреть свои астрофизик\\n']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_files_content = [open(file, mode='r', encoding='utf-8').read() for file in text_files]\n",
    "text_files_content[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "16a5f5d5-8741-4902-a9dd-709f4470f9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['совершенная технология',\n",
       " 'день слышался ей',\n",
       " 'что яна обложки сборников сказок',\n",
       " 'мышиный чепухи и',\n",
       " 'пересмотреть свои астрофизик']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_files_content = [x.strip() for x in text_files_content] # Уберем лишние пробелы\n",
    "text_files_content[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8082bd8f-297b-4312-b249-51dcf97eb05e",
   "metadata": {},
   "source": [
    "После того, как относительные пути до файлов и текстовые расшифровки получены, запишем их в файл `metadata.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b2f3fdf4-9ee8-47e5-b865-518359f283c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metadata.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    fields = ['file_name', 'transcription']\n",
    "    write = csv.writer(file)\n",
    "    write.writerow(fields)\n",
    "    for path, content in zip(audio_files, text_files_content):\n",
    "        write.writerow([path, content])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b0ad83-7d8d-49ce-b491-be8066626d48",
   "metadata": {},
   "source": [
    "Файл metadata.csv имеет вид `file_name, transcription`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b187d71-abb9-49c9-8a5d-4727a11296dc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Разделение данных на обучающую и тестовую выборку"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fec0ce-4260-4a47-a572-75fa7c2b3d92",
   "metadata": {},
   "source": [
    "Сформируем датасет с помощью функции `load_dataset`, передав в неё путь до папки с `metadata.csv` и `.opus` файлами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23d35509-bd75-49dd-a3a8-51c53eefb550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27942d36bd24a559bf272615f8b43d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/92277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"audiofolder\", data_dir=r\"Z:\\Code\\Uni\\ML\\Kursach\\Data\\asr_public_stories_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fd6b981-b209-4792-906e-ba26141d4e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16_000)) # Приведем столбец к нужному типу данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13171542-5309-4e6a-84ab-e2ba8ef4440c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'transcription'],\n",
       "        num_rows: 46138\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23939749-052f-4401-af9f-d9b0ed91dc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = dataset['train'].train_test_split(test_size=0.3)\n",
    "train = split['train']\n",
    "test = split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11846ebf-6e9d-4bc2-bee8-d6c964f6a31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio', 'transcription'],\n",
       "    num_rows: 32296\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d935e20-249f-46cb-94a5-42d97f930f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio', 'transcription'],\n",
       "    num_rows: 13842\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b68202-df7c-41f2-8b8d-7dfa5b1900f2",
   "metadata": {},
   "source": [
    "# Определение метрики качества модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0a0a51-7f31-4f44-a1d9-46570f4d8f05",
   "metadata": {},
   "source": [
    "Для определения качества модели распознавания речи используется метрика $WER$ - word error rate. Она рассчитывается на основании расстояния Левинштейна. $WER = \\frac{D}{N}$, где D - расстояние Левинштейна, а N - это количество слов в оригинальном слове. \n",
    "\n",
    "Чем меньше расстояние левинштейна, тем меньше числитель, тем меньше значение $WER$. Следовательно, чем меньше значение WER, тем лучше.\n",
    "\n",
    "Существует также метрика $W_{\\text{accuracy}} = 1 - WER$. Чем больше метрика точности, тем лучше"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b842623-5c9e-4f89-9ee6-8a79af24b42c",
   "metadata": {},
   "source": [
    "Расстояние Левинштайна (Levinstein distance) - это метрика, измерающая разность между двумя последовательностями символов. Разность рассчитывается как количество удалений, замен и вставок, которые необходимы для превращения одной последовательности символов в другую, например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "980f894a-c71f-41f7-a629-a65b7671630d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Здесь буква w заменена на v и добавлена буква h -> 2\n",
    "distance(\"lewenstein\", \"levenshtein\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4de08b-6fdf-486b-9e9f-200f46aea97f",
   "metadata": {},
   "source": [
    "# Качество предобученной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a291bc-be81-4f8b-b3c2-f8cb57a8571b",
   "metadata": {},
   "source": [
    "Загрузим модель, подключим вычисления на видеокарте. Создадим pipeline для применения модели\n",
    "\n",
    "Для чтения opus файлов потребуется установить и импортировать soundfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cc7304c-0768-408d-a3c4-921bae47cd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"openai/whisper-small\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a5b7c3-bc27-48da-bbf8-12a0f5858dd1",
   "metadata": {},
   "source": [
    "Протестируем модель на случайном элементе выборки. Посмотрим, какой результат выдала модель и какой результат ожидался:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46b7e5f5-d8f7-4575-b5b6-d3933f408bfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:694: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распознано:  и быстро-быстро заморгал окарьями глазами., сказано: быстро быстро заморгала карими глазами\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "index = random.randint(1, 1000)\n",
    "predicted = pipe(train[index]['audio'], generate_kwargs={\"language\": \"russian\"})\n",
    "source = train[index]['transcription']\n",
    "print(f'Распознано: {predicted[\"text\"]}, сказано: {source}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1fb1a44-83e1-4c80-9615-0d4e5e3d4e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_metric = load('wer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4d9864-5d0b-4936-86a0-2fa2af570725",
   "metadata": {},
   "source": [
    "## Проверим качество модели \n",
    "Для этого произведем распознавание речи на малом объеме данных (\\~700 элементов) и на всей тестовой выборке (~13 тысяч элементов). Результаты запишем в два списка: оригинал и распознанную речь."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe12301-b4cd-4f31-993b-6d263486afe0",
   "metadata": {},
   "source": [
    "Возьмем часть обучающей выборки (~700 элементов) и посчитаем качество модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f575dcb-061b-4e31-aea1-bfae4119941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_part = test[::20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dec0887c-21f0-4a70-b772-63a3707a12fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "693"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_part['audio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80fcecc7-aabd-432b-a329-a9b8fa0aaf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    }
   ],
   "source": [
    "n = len(test_part['audio'])\n",
    "references = []\n",
    "predictions = []\n",
    "for i in range(n):\n",
    "    predictions.append(pipe(test_part['audio'][i], generate_kwargs={\"language\": \"russian\"}))\n",
    "    references.append(test_part['transcription'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5deb0f5-9b2c-4a9a-90a5-ccc48e93adbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Таких красивых слов не бывает!',\n",
       " ' Наивно и уверенно в непоговорительности.',\n",
       " ' великолепно говорила, потирай руки.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_texts = [x['text'] for x in predictions]\n",
    "predictions_texts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01eaf6cf-daf5-4a70-80d8-cb3fb20b51eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.598"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wer = wer_metric.compute(references=references, predictions=predictions_texts)\n",
    "round(wer, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55e377d1-2ada-4b98-b742-b4fd1edb76ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.402"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_accuracy = 1 - wer\n",
    "round(w_accuracy, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08887dc0-26be-4632-89f3-8689dafb3f11",
   "metadata": {},
   "source": [
    "На малом объеме данных предобученная модель показала точность ~$40.2\\%$. Проверим точность на всей тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ec45a798-3bb9-4586-8916-f4b7f5e61a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                          | 0/866 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                                                  | 1/866 [00:01<15:09,  1.05s/it]\u001b[A\n",
      "  2%|█▌                                                                               | 17/866 [00:01<01:18, 10.83it/s]\u001b[A\n",
      "  4%|███                                                                              | 33/866 [00:02<01:00, 13.71it/s]\u001b[A\n",
      "  5%|████▍                                                                            | 47/866 [00:02<00:37, 22.01it/s]\u001b[A\n",
      "  6%|█████                                                                            | 54/866 [00:03<00:50, 15.96it/s]\u001b[A\n",
      "  8%|██████                                                                           | 65/866 [00:04<00:55, 14.33it/s]\u001b[A\n",
      "  9%|███████▍                                                                         | 80/866 [00:04<00:35, 22.37it/s]\u001b[A\n",
      " 10%|████████▏                                                                        | 87/866 [00:05<00:46, 16.77it/s]\u001b[A\n",
      " 11%|█████████                                                                        | 97/866 [00:06<00:51, 14.92it/s]\u001b[A\n",
      " 13%|██████████▍                                                                     | 113/866 [00:07<00:48, 15.46it/s]\u001b[A\n",
      " 15%|███████████▋                                                                    | 126/866 [00:07<00:34, 21.53it/s]\u001b[A\n",
      " 15%|████████████▎                                                                   | 133/866 [00:08<00:43, 16.86it/s]\u001b[A\n",
      " 17%|█████████████▍                                                                  | 145/866 [00:09<00:45, 15.70it/s]\u001b[A\n",
      " 19%|██████████████▊                                                                 | 161/866 [00:10<00:43, 16.19it/s]\u001b[A\n",
      " 20%|████████████████▏                                                               | 175/866 [00:10<00:30, 22.67it/s]\u001b[A\n",
      " 21%|████████████████▊                                                               | 182/866 [00:10<00:38, 17.73it/s]\u001b[A\n",
      " 22%|█████████████████▊                                                              | 193/866 [00:11<00:42, 15.87it/s]\u001b[A\n",
      " 24%|███████████████████▎                                                            | 209/866 [00:12<00:39, 16.46it/s]\u001b[A\n",
      " 26%|████████████████████▌                                                           | 223/866 [00:12<00:27, 22.99it/s]\u001b[A\n",
      " 27%|█████████████████████▏                                                          | 230/866 [00:13<00:37, 17.11it/s]\u001b[A\n",
      " 28%|██████████████████████▎                                                         | 241/866 [00:14<00:40, 15.59it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      " 30%|███████████████████████▋                                                        | 257/866 [00:15<00:39, 15.45it/s]\u001b[A\n",
      " 31%|████████████████████████▍                                                       | 265/866 [00:15<00:32, 18.65it/s]\u001b[A\n",
      " 32%|█████████████████████████▏                                                      | 273/866 [00:16<00:39, 15.20it/s]\u001b[A\n",
      " 33%|██████████████████████████▋                                                     | 289/866 [00:17<00:36, 15.88it/s]\u001b[A\n",
      " 35%|███████████████████████████▉                                                    | 303/866 [00:17<00:25, 22.47it/s]\u001b[A\n",
      " 36%|████████████████████████████▌                                                   | 309/866 [00:18<00:33, 16.74it/s]\u001b[A\n",
      " 37%|█████████████████████████████▋                                                  | 321/866 [00:19<00:34, 15.82it/s]\u001b[A\n",
      " 39%|███████████████████████████████▏                                                | 337/866 [00:20<00:33, 15.88it/s]\u001b[A\n",
      " 40%|████████████████████████████████▏                                               | 349/866 [00:20<00:24, 21.23it/s]\u001b[A\n",
      " 41%|████████████████████████████████▊                                               | 355/866 [00:21<00:32, 15.79it/s]\u001b[A\n",
      " 43%|██████████████████████████████████                                              | 369/866 [00:22<00:31, 15.84it/s]\u001b[A\n",
      " 44%|███████████████████████████████████▌                                            | 385/866 [00:23<00:29, 16.35it/s]\u001b[A\n",
      " 46%|████████████████████████████████████▊                                           | 399/866 [00:23<00:20, 22.73it/s]\u001b[A\n",
      " 47%|█████████████████████████████████████▌                                          | 406/866 [00:23<00:25, 17.77it/s]\u001b[A\n",
      " 48%|██████████████████████████████████████▌                                         | 417/866 [00:24<00:27, 16.19it/s]\u001b[A\n",
      " 50%|████████████████████████████████████████                                        | 433/866 [00:25<00:26, 16.53it/s]\u001b[A\n",
      " 52%|█████████████████████████████████████████▍                                      | 449/866 [00:26<00:25, 16.34it/s]\u001b[A\n",
      " 53%|██████████████████████████████████████████▋                                     | 462/866 [00:26<00:18, 21.81it/s]\u001b[A\n",
      " 54%|███████████████████████████████████████████▏                                    | 468/866 [00:27<00:24, 16.32it/s]\u001b[A\n",
      " 56%|████████████████████████████████████████████▍                                   | 481/866 [00:28<00:24, 15.95it/s]\u001b[A\n",
      " 57%|█████████████████████████████████████████████▉                                  | 497/866 [00:29<00:21, 16.98it/s]\u001b[A\n",
      " 59%|███████████████████████████████████████████████▍                                | 513/866 [00:30<00:20, 16.97it/s]\u001b[A\n",
      " 61%|████████████████████████████████████████████████▋                               | 527/866 [00:30<00:14, 23.07it/s]\u001b[A\n",
      " 62%|█████████████████████████████████████████████████▏                              | 533/866 [00:31<00:19, 17.27it/s]\u001b[A\n",
      " 63%|██████████████████████████████████████████████████▎                             | 545/866 [00:31<00:19, 16.65it/s]\u001b[A\n",
      " 65%|███████████████████████████████████████████████████▊                            | 561/866 [00:32<00:18, 16.91it/s]\u001b[A\n",
      " 66%|█████████████████████████████████████████████████████                           | 575/866 [00:32<00:12, 23.37it/s]\u001b[A\n",
      " 67%|█████████████████████████████████████████████████████▊                          | 582/866 [00:34<00:18, 15.50it/s]\u001b[A\n",
      " 68%|██████████████████████████████████████████████████████▌                         | 591/866 [00:34<00:14, 19.50it/s]\u001b[A\n",
      " 69%|███████████████████████████████████████████████████████▏                        | 597/866 [00:35<00:18, 14.76it/s]\u001b[A\n",
      " 70%|████████████████████████████████████████████████████████▎                       | 609/866 [00:35<00:17, 14.36it/s]\u001b[A\n",
      " 72%|█████████████████████████████████████████████████████████▋                      | 624/866 [00:35<00:10, 22.10it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      " 73%|██████████████████████████████████████████████████████████▎                     | 631/866 [00:38<00:23,  9.84it/s]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████▊                     | 636/866 [00:38<00:20, 11.17it/s]\u001b[A\n",
      " 74%|███████████████████████████████████████████████████████████▏                    | 641/866 [00:39<00:23,  9.45it/s]\u001b[A\n",
      " 76%|████████████████████████████████████████████████████████████▋                   | 657/866 [00:40<00:17, 12.05it/s]\u001b[A\n",
      " 78%|██████████████████████████████████████████████████████████████                  | 672/866 [00:40<00:10, 18.75it/s]\u001b[A\n",
      " 78%|██████████████████████████████████████████████████████████████▋                 | 679/866 [00:41<00:12, 15.07it/s]\u001b[A\n",
      " 80%|███████████████████████████████████████████████████████████████▋                | 689/866 [00:41<00:12, 14.14it/s]\u001b[A\n",
      " 81%|█████████████████████████████████████████████████████████████████▏              | 705/866 [00:42<00:10, 15.45it/s]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████████████▌             | 720/866 [00:42<00:06, 22.52it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████████▏            | 727/866 [00:43<00:08, 17.13it/s]\u001b[A\n",
      " 85%|████████████████████████████████████████████████████████████████████            | 737/866 [00:44<00:08, 14.54it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████████████████████████████████████▏          | 749/866 [00:44<00:05, 20.30it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████████▊          | 756/866 [00:45<00:06, 15.83it/s]\u001b[A\n",
      " 89%|███████████████████████████████████████████████████████████████████████         | 769/866 [00:46<00:06, 15.68it/s]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████▌       | 785/866 [00:47<00:04, 16.69it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████████████████████████████████████████▉      | 801/866 [00:48<00:03, 17.00it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 816/866 [00:48<00:02, 23.80it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████████████████████████████████████████    | 823/866 [00:49<00:02, 17.75it/s]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████████▉   | 833/866 [00:50<00:02, 15.49it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████████████████████████████████████████▍ | 849/866 [00:50<00:01, 16.17it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████▉| 865/866 [00:51<00:00, 16.31it/s]\u001b[A\n",
      "879it [00:52, 22.25it/s]                                                                                               \u001b[A\n",
      "885it [00:52, 16.13it/s]\u001b[A\n",
      "897it [00:53, 14.83it/s]\u001b[A\n",
      "910it [00:53, 20.78it/s]\u001b[A\n",
      "917it [00:54, 15.94it/s]\u001b[A\n",
      "929it [00:55, 14.64it/s]\u001b[A\n",
      "941it [00:55, 20.34it/s]\u001b[A\n",
      "948it [00:56, 15.11it/s]\u001b[A\n",
      "961it [00:57, 14.95it/s]\u001b[A\n",
      "977it [00:58, 15.87it/s]\u001b[A\n",
      "992it [00:58, 22.81it/s]\u001b[A\n",
      "999it [00:59, 16.02it/s]\u001b[A\n",
      "1009it [01:01, 12.39it/s]\u001b[A\n",
      "1017it [01:01, 15.48it/s]\u001b[A\n",
      "1025it [01:01, 13.29it/s]\u001b[A\n",
      "1041it [01:02, 15.10it/s]\u001b[A\n",
      "1057it [01:03, 15.86it/s]\u001b[A\n",
      "1072it [01:03, 22.57it/s]\u001b[A\n",
      "1079it [01:04, 16.95it/s]\u001b[A\n",
      "1089it [01:05, 14.87it/s]\u001b[A\n",
      "1104it [01:05, 22.16it/s]\u001b[A\n",
      "1111it [01:06, 17.11it/s]\u001b[A\n",
      "1121it [01:07, 15.15it/s]\u001b[A\n",
      "1136it [01:07, 23.01it/s]\u001b[A\n",
      "1144it [01:08, 15.71it/s]\u001b[A\n",
      "1153it [01:10,  8.98it/s]\u001b[A\n",
      "1157it [01:10, 10.01it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "1161it [01:10, 11.34it/s]\u001b[A\n",
      "1165it [01:11, 12.96it/s]\u001b[A\n",
      "1169it [01:11,  9.36it/s]\u001b[A\n",
      "1185it [01:12, 12.32it/s]\u001b[A\n",
      "1198it [01:13, 19.06it/s]\u001b[A\n",
      "1204it [01:13, 14.14it/s]\u001b[A\n",
      "1217it [01:14, 14.87it/s]\u001b[A\n",
      "1233it [01:15, 15.19it/s]\u001b[A\n",
      "1245it [01:15, 20.60it/s]\u001b[A\n",
      "1251it [01:16, 13.44it/s]\u001b[A\n",
      "1260it [01:17, 17.55it/s]\u001b[A\n",
      "1266it [01:17, 13.40it/s]\u001b[A\n",
      "1281it [01:19, 13.33it/s]\u001b[A\n",
      "1291it [01:19, 17.70it/s]\u001b[A\n",
      "1297it [01:20, 13.34it/s]\u001b[A\n",
      "1312it [01:20, 21.43it/s]\u001b[A\n",
      "1320it [01:20, 16.81it/s]\u001b[A\n",
      "1329it [01:21, 15.02it/s]\u001b[A\n",
      "1345it [01:22, 14.98it/s]\u001b[A\n",
      "1356it [01:22, 19.91it/s]\u001b[A\n",
      "1362it [01:23, 14.07it/s]\u001b[A\n",
      "1373it [01:23, 19.58it/s]\u001b[A\n",
      "1379it [01:24, 14.04it/s]\u001b[A\n",
      "1392it [01:25, 21.31it/s]\u001b[A\n",
      "1399it [01:25, 14.95it/s]\u001b[A\n",
      "1409it [01:26, 13.97it/s]\u001b[A\n",
      "1425it [01:27, 15.63it/s]\u001b[A\n",
      "1441it [01:28, 16.79it/s]\u001b[A\n",
      "1457it [01:29, 16.43it/s]\u001b[A\n",
      "1468it [01:29, 20.97it/s]\u001b[A\n",
      "1473it [01:30, 15.24it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "1488it [01:30, 23.06it/s]\u001b[A\n",
      "1495it [01:31, 15.91it/s]\u001b[A\n",
      "1505it [01:32, 14.37it/s]\u001b[A\n",
      "1521it [01:33, 15.13it/s]\u001b[A\n",
      "1531it [01:33, 19.45it/s]\u001b[A\n",
      "1537it [01:34, 14.78it/s]\u001b[A\n",
      "1553it [01:35, 15.38it/s]\u001b[A\n",
      "1566it [01:35, 21.42it/s]\u001b[A\n",
      "1572it [01:37,  9.83it/s]\u001b[A\n",
      "1577it [01:37, 11.14it/s]\u001b[A\n",
      "1581it [01:37, 12.45it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "1585it [01:38,  9.30it/s]\u001b[A\n",
      "1601it [01:39, 12.23it/s]\u001b[A\n",
      "1617it [01:40, 13.58it/s]\u001b[A\n",
      "1629it [01:40, 18.80it/s]\u001b[A\n",
      "1635it [01:41, 13.50it/s]\u001b[A\n",
      "1646it [01:41, 18.86it/s]\u001b[A\n",
      "1652it [01:42, 12.70it/s]\u001b[A\n",
      "1662it [01:43, 17.64it/s]\u001b[A\n",
      "1668it [01:44, 12.62it/s]\u001b[A\n",
      "1680it [01:44, 19.21it/s]\u001b[A\n",
      "1687it [01:44, 14.77it/s]\u001b[A\n",
      "1697it [01:45, 13.92it/s]\u001b[A\n",
      "1713it [01:46, 14.59it/s]\u001b[A\n",
      "1729it [01:49, 10.13it/s]\u001b[A\n",
      "1733it [01:49, 11.02it/s]\u001b[A\n",
      "1737it [01:49, 12.16it/s]\u001b[A\n",
      "1741it [01:49, 13.55it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "1745it [01:51,  5.62it/s]\u001b[A\n",
      "1749it [01:52,  6.86it/s]\u001b[A\n",
      "1753it [01:52,  8.43it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "1757it [01:52, 10.34it/s]\u001b[A\n",
      "1761it [01:53,  7.06it/s]\u001b[A\n",
      "1769it [01:53, 11.65it/s]\u001b[A\n",
      "1777it [01:54, 10.42it/s]\u001b[A\n",
      "1793it [01:55, 12.85it/s]\u001b[A\n",
      "1808it [01:55, 20.57it/s]\u001b[A\n",
      "1815it [01:56, 14.98it/s]\u001b[A\n",
      "1825it [01:57, 13.63it/s]\u001b[A\n",
      "1840it [01:57, 21.26it/s]\u001b[A\n",
      "1847it [01:58, 16.20it/s]\u001b[A\n",
      "1857it [01:59, 14.76it/s]\u001b[A\n",
      "1873it [01:59, 16.19it/s]\u001b[A\n",
      "1889it [02:00, 16.60it/s]\u001b[A\n",
      "1905it [02:01, 16.48it/s]\u001b[A\n",
      "1919it [02:01, 22.38it/s]\u001b[A\n",
      "1925it [02:02, 16.59it/s]\u001b[A\n",
      "1937it [02:03, 15.74it/s]\u001b[A\n",
      "1953it [02:04, 16.07it/s]\u001b[A\n",
      "1968it [02:04, 22.76it/s]\u001b[A\n",
      "1975it [02:05, 17.32it/s]\u001b[A\n",
      "1985it [02:06, 15.68it/s]\u001b[A\n",
      "2001it [02:07, 16.26it/s]\u001b[A\n",
      "2015it [02:07, 22.69it/s]\u001b[A\n",
      "2022it [02:08, 16.18it/s]\u001b[A\n",
      "2033it [02:09, 14.27it/s]\u001b[A\n",
      "2045it [02:09, 19.75it/s]\u001b[A\n",
      "2051it [02:10, 14.29it/s]\u001b[A\n",
      "2064it [02:10, 21.06it/s]\u001b[A\n",
      "2071it [02:11, 15.95it/s]\u001b[A\n",
      "2081it [02:12, 13.48it/s]\u001b[A\n",
      "2092it [02:12, 18.80it/s]\u001b[A\n",
      "2098it [02:13, 13.87it/s]\u001b[A\n",
      "2112it [02:13, 21.70it/s]\u001b[A\n",
      "2119it [02:14, 16.19it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "2129it [02:14, 14.56it/s]\u001b[A\n",
      "2145it [02:15, 16.09it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "2161it [02:16, 16.96it/s]\u001b[A\n",
      "2177it [02:17, 16.66it/s]\u001b[A\n",
      "2191it [02:17, 22.70it/s]\u001b[A\n",
      "2197it [02:18, 16.73it/s]\u001b[A\n",
      "2209it [02:19, 14.82it/s]\u001b[A\n",
      "2221it [02:19, 20.19it/s]\u001b[A\n",
      "2227it [02:20, 15.40it/s]\u001b[A\n",
      "2241it [02:21, 15.67it/s]\u001b[A\n",
      "2256it [02:21, 23.23it/s]\u001b[A\n",
      "2263it [02:22, 17.18it/s]\u001b[A\n",
      "2273it [02:23, 14.37it/s]\u001b[A\n",
      "2282it [02:23, 18.51it/s]\u001b[A\n",
      "2289it [02:24, 14.40it/s]\u001b[A\n",
      "2305it [02:25, 15.96it/s]\u001b[A\n",
      "2321it [02:26, 16.17it/s]\u001b[A\n",
      "2334it [02:26, 22.01it/s]\u001b[A\n",
      "2340it [02:27, 16.42it/s]\u001b[A\n",
      "2353it [02:28, 15.62it/s]\u001b[A\n",
      "2367it [02:28, 22.49it/s]\u001b[A\n",
      "2374it [02:28, 16.84it/s]\u001b[A\n",
      "2385it [02:29, 14.54it/s]\u001b[A\n",
      "2397it [02:30, 20.32it/s]\u001b[A\n",
      "2404it [02:30, 15.53it/s]\u001b[A\n",
      "2417it [02:31, 14.95it/s]\u001b[A\n",
      "2430it [02:31, 21.36it/s]\u001b[A\n",
      "2437it [02:32, 16.27it/s]\u001b[A\n",
      "2449it [02:34,  9.76it/s]\u001b[A\n",
      "2453it [02:35, 10.78it/s]\u001b[A\n",
      "2457it [02:35, 12.05it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "2461it [02:35, 13.62it/s]\u001b[A\n",
      "2465it [02:36,  9.78it/s]\u001b[A\n",
      "2481it [02:37, 12.90it/s]\u001b[A\n",
      "2495it [02:37, 20.47it/s]\u001b[A\n",
      "2501it [02:38, 14.77it/s]\u001b[A\n",
      "2513it [02:39, 13.53it/s]\u001b[A\n",
      "2524it [02:39, 18.78it/s]\u001b[A\n",
      "2530it [02:39, 14.25it/s]\u001b[A\n",
      "2545it [02:40, 15.20it/s]\u001b[A\n",
      "2561it [02:41, 15.97it/s]\u001b[A\n",
      "2576it [02:41, 22.96it/s]\u001b[A\n",
      "2583it [02:42, 17.68it/s]\u001b[A\n",
      "2593it [02:43, 15.29it/s]\u001b[A\n",
      "2608it [02:43, 22.85it/s]\u001b[A\n",
      "2615it [02:44, 17.34it/s]\u001b[A\n",
      "2625it [02:45, 14.90it/s]\u001b[A\n",
      "2638it [02:45, 21.53it/s]\u001b[A\n",
      "2645it [02:46, 15.84it/s]\u001b[A\n",
      "2657it [02:47, 14.83it/s]\u001b[A\n",
      "2673it [02:48, 15.49it/s]\u001b[A\n",
      "2688it [02:48, 22.37it/s]\u001b[A\n",
      "2695it [02:49, 16.40it/s]\u001b[A\n",
      "2705it [02:50, 14.41it/s]\u001b[A\n",
      "2719it [02:50, 21.13it/s]\u001b[A\n",
      "2726it [02:51, 16.10it/s]\u001b[A\n",
      "2737it [02:52, 14.45it/s]\u001b[A\n",
      "2752it [02:52, 21.93it/s]\u001b[A\n",
      "2760it [02:53, 16.40it/s]\u001b[A\n",
      "2769it [02:53, 14.44it/s]\u001b[A\n",
      "2785it [02:54, 15.31it/s]\u001b[A\n",
      "2799it [02:54, 21.75it/s]\u001b[A\n",
      "2806it [02:55, 15.80it/s]\u001b[A\n",
      "2817it [02:56, 14.92it/s]\u001b[A\n",
      "2833it [02:57, 16.69it/s]\u001b[A\n",
      "2849it [02:58, 16.61it/s]\u001b[A\n",
      "2861it [02:58, 21.73it/s]\u001b[A\n",
      "2867it [02:59, 16.45it/s]\u001b[A\n",
      "2881it [03:00, 16.09it/s]\u001b[A\n",
      "2895it [03:00, 22.89it/s]\u001b[A\n",
      "2902it [03:01, 17.76it/s]\u001b[A\n",
      "2913it [03:02, 15.71it/s]\u001b[A\n",
      "2927it [03:02, 22.93it/s]\u001b[A\n",
      "2934it [03:02, 17.36it/s]\u001b[A\n",
      "2945it [03:03, 15.86it/s]\u001b[A\n",
      "2961it [03:04, 16.78it/s]\u001b[A\n",
      "2977it [03:05, 16.41it/s]\u001b[A\n",
      "2988it [03:05, 21.08it/s]\u001b[A\n",
      "2994it [03:06, 15.40it/s]\u001b[A\n",
      "3006it [03:06, 21.45it/s]\u001b[A\n",
      "3013it [03:07, 14.66it/s]\u001b[A\n",
      "3023it [03:07, 19.70it/s]\u001b[A\n",
      "3029it [03:08, 13.94it/s]\u001b[A\n",
      "3041it [03:09, 13.91it/s]\u001b[A\n",
      "3057it [03:10, 15.34it/s]\u001b[A\n",
      "3073it [03:11, 16.41it/s]\u001b[A\n",
      "3089it [03:12, 17.21it/s]\u001b[A\n",
      "3105it [03:13, 17.61it/s]\u001b[A\n",
      "3121it [03:14, 17.21it/s]\u001b[A\n",
      "3133it [03:14, 22.03it/s]\u001b[A\n",
      "3138it [03:15, 16.75it/s]\u001b[A\n",
      "3153it [03:15, 17.23it/s]\u001b[A\n",
      "3169it [03:16, 17.41it/s]\u001b[A\n",
      "3185it [03:17, 17.50it/s]\u001b[A\n",
      "3200it [03:17, 24.09it/s]\u001b[A\n",
      "3207it [03:18, 18.00it/s]\u001b[A\n",
      "3217it [03:19, 16.06it/s]\u001b[A\n",
      "3230it [03:19, 22.44it/s]\u001b[A\n",
      "3237it [03:20, 17.07it/s]\u001b[A\n",
      "3249it [03:21, 15.30it/s]\u001b[A\n",
      "3261it [03:21, 21.20it/s]\u001b[A\n",
      "3268it [03:22, 16.06it/s]\u001b[A\n",
      "3281it [03:23, 14.96it/s]\u001b[A\n",
      "3293it [03:23, 20.75it/s]\u001b[A\n",
      "3299it [03:24, 14.84it/s]\u001b[A\n",
      "3312it [03:24, 21.90it/s]\u001b[A\n",
      "3319it [03:25, 15.35it/s]\u001b[A\n",
      "3329it [03:26, 14.09it/s]\u001b[A\n",
      "3345it [03:26, 15.88it/s]\u001b[A\n",
      "3361it [03:27, 16.73it/s]\u001b[A\n",
      "3377it [03:28, 16.25it/s]\u001b[A\n",
      "3388it [03:28, 20.71it/s]\u001b[A\n",
      "3393it [03:29, 15.15it/s]\u001b[A\n",
      "3407it [03:29, 22.32it/s]\u001b[A\n",
      "3414it [03:30, 16.67it/s]\u001b[A\n",
      "3425it [03:31, 15.18it/s]\u001b[A\n",
      "3441it [03:32, 16.27it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "3457it [03:33, 14.91it/s]\u001b[A\n",
      "3465it [03:33, 17.89it/s]\u001b[A\n",
      "3473it [03:34, 14.59it/s]\u001b[A\n",
      "3489it [03:35, 13.94it/s]\u001b[A\n",
      "3498it [03:36, 17.44it/s]\u001b[A\n",
      "3505it [03:36, 13.76it/s]\u001b[A\n",
      "3521it [03:37, 14.57it/s]\u001b[A\n",
      "3535it [03:38, 20.82it/s]\u001b[A\n",
      "3541it [03:38, 15.23it/s]\u001b[A\n",
      "3553it [03:39, 14.39it/s]\u001b[A\n",
      "3569it [03:40, 15.08it/s]\u001b[A\n",
      "3585it [03:41, 15.17it/s]\u001b[A\n",
      "3598it [03:42, 20.38it/s]\u001b[A\n",
      "3604it [03:42, 15.14it/s]\u001b[A\n",
      "3617it [03:43, 15.04it/s]\u001b[A\n",
      "3633it [03:44, 15.75it/s]\u001b[A\n",
      "3649it [03:45, 16.01it/s]\u001b[A\n",
      "3659it [03:45, 19.95it/s]\u001b[A\n",
      "3665it [03:46, 14.84it/s]\u001b[A\n",
      "3680it [03:46, 22.40it/s]\u001b[A\n",
      "3687it [03:47, 15.62it/s]\u001b[A\n",
      "3697it [03:48, 13.11it/s]\u001b[A\n",
      "3709it [03:49, 18.54it/s]\u001b[A\n",
      "3716it [03:50, 13.61it/s]\u001b[A\n",
      "3729it [03:50, 13.96it/s]\u001b[A\n",
      "3745it [03:52, 13.22it/s]\u001b[A\n",
      "3753it [03:52, 16.12it/s]\u001b[A\n",
      "3761it [03:53, 13.12it/s]\u001b[A\n",
      "3775it [03:53, 19.80it/s]\u001b[A\n",
      "3782it [03:54, 14.56it/s]\u001b[A\n",
      "3793it [03:55, 13.39it/s]\u001b[A\n",
      "3807it [03:55, 20.07it/s]\u001b[A\n",
      "3814it [03:56, 14.98it/s]\u001b[A\n",
      "3825it [03:57, 13.62it/s]\u001b[A\n",
      "3834it [03:57, 17.64it/s]\u001b[A\n",
      "3841it [03:58, 13.24it/s]\u001b[A\n",
      "3854it [03:58, 20.03it/s]\u001b[A\n",
      "3861it [03:59, 14.37it/s]\u001b[A\n",
      "3873it [04:00, 12.34it/s]\u001b[A\n",
      "3882it [04:00, 16.18it/s]\u001b[A\n",
      "3889it [04:01, 12.90it/s]\u001b[A\n",
      "3905it [04:02, 14.66it/s]\u001b[A\n",
      "3921it [04:04,  9.99it/s]\u001b[A\n",
      "3925it [04:05, 10.88it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "3929it [04:05, 12.04it/s]\u001b[A\n",
      "3933it [04:05, 13.47it/s]\u001b[A\n",
      "3937it [04:06,  9.59it/s]\u001b[A\n",
      "3953it [04:07, 12.14it/s]\u001b[A\n",
      "3966it [04:07, 18.52it/s]\u001b[A\n",
      "3972it [04:08, 13.85it/s]\u001b[A\n",
      "3985it [04:09, 14.13it/s]\u001b[A\n",
      "4001it [04:10, 15.22it/s]\u001b[A\n",
      "4017it [04:10, 15.98it/s]\u001b[A\n",
      "4031it [04:11, 22.05it/s]\u001b[A\n",
      "4037it [04:13, 10.27it/s]\u001b[A\n",
      "4042it [04:13, 11.56it/s]\u001b[A\n",
      "4046it [04:13, 12.95it/s]\u001b[A\n",
      "4050it [04:14,  9.18it/s]\u001b[A\n",
      "4062it [04:14, 15.38it/s]\u001b[A\n",
      "4068it [04:15, 11.84it/s]\u001b[A\n",
      "4081it [04:16, 12.69it/s]\u001b[A\n",
      "4097it [04:17, 14.40it/s]\u001b[A\n",
      "4113it [04:18, 14.40it/s]\u001b[A\n",
      "4124it [04:18, 18.78it/s]\u001b[A\n",
      "4129it [04:19, 14.14it/s]\u001b[A\n",
      "4145it [04:20, 14.96it/s]\u001b[A\n",
      "4160it [04:20, 21.85it/s]\u001b[A\n",
      "4167it [04:21, 15.82it/s]\u001b[A\n",
      "4177it [04:22, 13.82it/s]\u001b[A\n",
      "4191it [04:22, 20.40it/s]\u001b[A\n",
      "4198it [04:23, 15.48it/s]\u001b[A\n",
      "4209it [04:24, 13.63it/s]\u001b[A\n",
      "4222it [04:24, 19.74it/s]\u001b[A\n",
      "4229it [04:25, 14.62it/s]\u001b[A\n",
      "4239it [04:25, 19.64it/s]\u001b[A\n",
      "4246it [04:26, 14.66it/s]\u001b[A\n",
      "4257it [04:27, 13.20it/s]\u001b[A\n",
      "4271it [04:27, 20.15it/s]\u001b[A\n",
      "4278it [04:28, 14.86it/s]\u001b[A\n",
      "4289it [04:29, 12.68it/s]\u001b[A\n",
      "4300it [04:29, 17.54it/s]\u001b[A\n",
      "4306it [04:30, 13.20it/s]\u001b[A\n",
      "4321it [04:31, 14.43it/s]\u001b[A\n",
      "4337it [04:32, 15.57it/s]\u001b[A\n",
      "4353it [04:33, 16.33it/s]\u001b[A\n",
      "4369it [04:34, 15.48it/s]\u001b[A\n",
      "4379it [04:34, 19.22it/s]\u001b[A\n",
      "4385it [04:35, 15.02it/s]\u001b[A\n",
      "4401it [04:36, 15.78it/s]\u001b[A\n",
      "4416it [04:36, 22.65it/s]\u001b[A\n",
      "4423it [04:37, 16.30it/s]\u001b[A\n",
      "4433it [04:38, 14.45it/s]\u001b[A\n",
      "4449it [04:39, 14.12it/s]\u001b[A\n",
      "4459it [04:39, 18.04it/s]\u001b[A\n",
      "4465it [04:40, 12.41it/s]\u001b[A\n",
      "4474it [04:40, 16.28it/s]\u001b[A\n",
      "4481it [04:41, 12.27it/s]\u001b[A\n",
      "4490it [04:42, 16.58it/s]\u001b[A\n",
      "4497it [04:42, 12.76it/s]\u001b[A\n",
      "4511it [04:43, 20.56it/s]\u001b[A\n",
      "4518it [04:45,  8.71it/s]\u001b[A\n",
      "4523it [04:45, 10.10it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "4528it [04:45, 11.80it/s]\u001b[A\n",
      "4532it [04:46,  9.14it/s]\u001b[A\n",
      "4545it [04:47,  9.21it/s]\u001b[A\n",
      "4553it [04:48, 12.40it/s]\u001b[A\n",
      "4560it [04:48, 15.93it/s]\u001b[A\n",
      "4565it [04:49, 11.59it/s]\u001b[A\n",
      "4577it [04:49, 12.23it/s]\u001b[A\n",
      "4593it [04:51, 13.31it/s]\u001b[A\n",
      "4605it [04:51, 18.63it/s]\u001b[A\n",
      "4611it [04:52, 13.56it/s]\u001b[A\n",
      "4624it [04:52, 20.19it/s]\u001b[A\n",
      "4631it [04:53, 15.22it/s]\u001b[A\n",
      "4641it [04:53, 14.14it/s]\u001b[A\n",
      "4657it [04:54, 15.54it/s]\u001b[A\n",
      "4673it [04:55, 15.82it/s]\u001b[A\n",
      "4686it [04:55, 21.53it/s]\u001b[A\n",
      "4692it [04:56, 15.78it/s]\u001b[A\n",
      "4705it [04:58,  9.99it/s]\u001b[A\n",
      "4709it [04:59, 10.96it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "4713it [04:59, 12.16it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "4717it [04:59, 13.71it/s]\u001b[A\n",
      "4721it [05:00,  9.46it/s]\u001b[A\n",
      "4737it [05:01, 12.08it/s]\u001b[A\n",
      "4750it [05:01, 18.54it/s]\u001b[A\n",
      "4756it [05:02, 13.98it/s]\u001b[A\n",
      "4769it [05:03, 13.07it/s]\u001b[A\n",
      "4780it [05:03, 18.09it/s]\u001b[A\n",
      "4786it [05:04, 13.66it/s]\u001b[A\n",
      "4801it [05:05, 14.82it/s]\u001b[A\n",
      "4817it [05:06, 14.59it/s]\u001b[A\n",
      "4829it [05:06, 19.64it/s]\u001b[A\n",
      "4835it [05:07, 14.80it/s]\u001b[A\n",
      "4849it [05:08, 15.13it/s]\u001b[A\n",
      "4865it [05:09, 15.85it/s]\u001b[A\n",
      "4880it [05:09, 22.54it/s]\u001b[A\n",
      "4887it [05:10, 16.48it/s]\u001b[A\n",
      "4897it [05:11, 14.59it/s]\u001b[A\n",
      "4913it [05:11, 15.72it/s]\u001b[A\n",
      "4929it [05:14, 11.04it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "4932it [05:14, 11.57it/s]\u001b[A\n",
      "4936it [05:14, 12.69it/s]\u001b[A\n",
      "4940it [05:14, 14.10it/s]\u001b[A\n",
      "4944it [05:14, 15.76it/s]\u001b[A\n",
      "4947it [05:17,  5.32it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "4951it [05:17,  6.69it/s]\u001b[A\n",
      "4955it [05:17,  8.40it/s]\u001b[A\n",
      "4959it [05:17, 10.48it/s]\u001b[A\n",
      "4962it [05:18,  7.23it/s]\u001b[A\n",
      "4977it [05:19, 11.36it/s]\u001b[A\n",
      "4993it [05:20, 13.85it/s]\u001b[A\n",
      "5009it [05:20, 15.06it/s]\u001b[A\n",
      "5024it [05:21, 22.08it/s]\u001b[A\n",
      "5030it [05:22, 15.22it/s]\u001b[A\n",
      "5041it [05:23, 13.73it/s]\u001b[A\n",
      "5054it [05:23, 19.73it/s]\u001b[A\n",
      "5061it [05:24, 14.79it/s]\u001b[A\n",
      "5073it [05:25, 13.78it/s]\u001b[A\n",
      "5086it [05:25, 19.80it/s]\u001b[A\n",
      "5093it [05:26, 14.64it/s]\u001b[A\n",
      "5105it [05:27, 13.80it/s]\u001b[A\n",
      "5119it [05:27, 20.37it/s]\u001b[A\n",
      "5126it [05:28, 15.56it/s]\u001b[A\n",
      "5137it [05:28, 14.38it/s]\u001b[A\n",
      "5153it [05:29, 15.37it/s]\u001b[A\n",
      "5169it [05:31, 11.76it/s]\u001b[A\n",
      "5174it [05:31, 13.08it/s]\u001b[A\n",
      "5178it [05:32, 14.39it/s]\u001b[A\n",
      "5182it [05:32, 16.01it/s]\u001b[A\n",
      "5186it [05:32, 11.12it/s]\u001b[A\n",
      "5201it [05:33, 13.35it/s]\u001b[A\n",
      "5217it [05:34, 14.89it/s]\u001b[A\n",
      "5233it [05:35, 15.69it/s]\u001b[A\n",
      "5249it [05:36, 16.28it/s]\u001b[A\n",
      "5265it [05:37, 16.99it/s]\u001b[A\n",
      "5281it [05:38, 16.98it/s]\u001b[A\n",
      "5295it [05:38, 22.74it/s]\u001b[A\n",
      "5301it [05:39, 16.70it/s]\u001b[A\n",
      "5312it [05:39, 21.90it/s]\u001b[A\n",
      "5318it [05:40, 15.41it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "5329it [05:41, 14.12it/s]\u001b[A\n",
      "5345it [05:42, 15.16it/s]\u001b[A\n",
      "5360it [05:42, 22.02it/s]\u001b[A\n",
      "5367it [05:43, 14.86it/s]\u001b[A\n",
      "5376it [05:43, 18.91it/s]\u001b[A\n",
      "5382it [05:44, 13.22it/s]\u001b[A\n",
      "5393it [05:45, 12.37it/s]\u001b[A\n",
      "5406it [05:45, 18.44it/s]\u001b[A\n",
      "5413it [05:46, 14.16it/s]\u001b[A\n",
      "5425it [05:47, 13.49it/s]\u001b[A\n",
      "5439it [05:47, 20.12it/s]\u001b[A\n",
      "5446it [05:48, 15.84it/s]\u001b[A\n",
      "5457it [05:49, 14.80it/s]\u001b[A\n",
      "5473it [05:50, 14.29it/s]\u001b[A\n",
      "5482it [05:50, 17.92it/s]\u001b[A\n",
      "5489it [05:51, 13.90it/s]\u001b[A\n",
      "5505it [05:52, 13.81it/s]\u001b[A\n",
      "5515it [05:52, 17.86it/s]\u001b[A\n",
      "5521it [05:53, 13.01it/s]\u001b[A\n",
      "5533it [05:53, 18.78it/s]\u001b[A\n",
      "5539it [05:54, 14.26it/s]\u001b[A\n",
      "5553it [05:55, 14.79it/s]\u001b[A\n",
      "5569it [05:56, 15.87it/s]\u001b[A\n",
      "5585it [05:57, 16.68it/s]\u001b[A\n",
      "5601it [05:58, 17.34it/s]\u001b[A\n",
      "5617it [05:59, 15.77it/s]\u001b[A\n",
      "5626it [05:59, 18.96it/s]\u001b[A\n",
      "5633it [06:00, 14.27it/s]\u001b[A\n",
      "5645it [06:00, 19.73it/s]\u001b[A\n",
      "5651it [06:01, 13.87it/s]\u001b[A\n",
      "5662it [06:01, 19.35it/s]\u001b[A\n",
      "5669it [06:03, 12.86it/s]\u001b[A\n",
      "5678it [06:03, 17.20it/s]\u001b[A\n",
      "5684it [06:03, 13.14it/s]\u001b[A\n",
      "5697it [06:04, 13.86it/s]\u001b[A\n",
      "5713it [06:05, 15.39it/s]\u001b[A\n",
      "5728it [06:05, 22.63it/s]\u001b[A\n",
      "5735it [06:06, 16.91it/s]\u001b[A\n",
      "5745it [06:07, 14.33it/s]\u001b[A\n",
      "5757it [06:07, 20.08it/s]\u001b[A\n",
      "5764it [06:08, 15.25it/s]\u001b[A\n",
      "5777it [06:09, 14.92it/s]\u001b[A\n",
      "5793it [06:10, 15.73it/s]\u001b[A\n",
      "5809it [06:11, 16.18it/s]\u001b[A\n",
      "5824it [06:11, 22.72it/s]\u001b[A\n",
      "5831it [06:12, 17.41it/s]\u001b[A\n",
      "5841it [06:13, 15.08it/s]\u001b[A\n",
      "5856it [06:13, 22.36it/s]\u001b[A\n",
      "5863it [06:14, 16.60it/s]\u001b[A\n",
      "5873it [06:15, 14.69it/s]\u001b[A\n",
      "5889it [06:15, 15.61it/s]\u001b[A\n",
      "5905it [06:16, 16.16it/s]\u001b[A\n",
      "5921it [06:17, 16.44it/s]\u001b[A\n",
      "5936it [06:17, 22.76it/s]\u001b[A\n",
      "5943it [06:18, 17.09it/s]\u001b[A\n",
      "5953it [06:19, 14.37it/s]\u001b[A\n",
      "5965it [06:19, 19.68it/s]\u001b[A\n",
      "5971it [06:20, 14.99it/s]\u001b[A\n",
      "5985it [06:21, 14.98it/s]\u001b[A\n",
      "5999it [06:21, 21.75it/s]\u001b[A\n",
      "6006it [06:22, 16.29it/s]\u001b[A\n",
      "6017it [06:23, 14.63it/s]\u001b[A\n",
      "6033it [06:24, 15.13it/s]\u001b[A\n",
      "6046it [06:24, 20.89it/s]\u001b[A\n",
      "6053it [06:25, 16.16it/s]\u001b[A\n",
      "6065it [06:26, 15.20it/s]\u001b[A\n",
      "6081it [06:27, 15.81it/s]\u001b[A\n",
      "6096it [06:27, 22.57it/s]\u001b[A\n",
      "6103it [06:28, 15.25it/s]\u001b[A\n",
      "6113it [06:29, 13.66it/s]\u001b[A\n",
      "6127it [06:29, 19.98it/s]\u001b[A\n",
      "6134it [06:30, 15.71it/s]\u001b[A\n",
      "6145it [06:31, 14.46it/s]\u001b[A\n",
      "6160it [06:31, 21.88it/s]\u001b[A\n",
      "6167it [06:32, 16.93it/s]\u001b[A\n",
      "6177it [06:33, 14.68it/s]\u001b[A\n",
      "6193it [06:34, 15.80it/s]\u001b[A\n",
      "6208it [06:34, 22.95it/s]\u001b[A\n",
      "6215it [06:35, 16.84it/s]\u001b[A\n",
      "6225it [06:36, 14.09it/s]\u001b[A\n",
      "6236it [06:36, 19.09it/s]\u001b[A\n",
      "6242it [06:36, 14.84it/s]\u001b[A\n",
      "6257it [06:37, 14.93it/s]\u001b[A\n",
      "6268it [06:38, 20.09it/s]\u001b[A\n",
      "6274it [06:38, 14.84it/s]\u001b[A\n",
      "6289it [06:39, 14.87it/s]\u001b[A\n",
      "6303it [06:40, 21.56it/s]\u001b[A\n",
      "6310it [06:41, 15.24it/s]\u001b[A\n",
      "6321it [06:42, 13.47it/s]\u001b[A\n",
      "6334it [06:42, 19.38it/s]\u001b[A\n",
      "6341it [06:44,  8.82it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "6346it [06:44, 10.09it/s]\u001b[A\n",
      "6350it [06:44, 11.37it/s]\u001b[A\n",
      "6354it [06:46,  8.06it/s]\u001b[A\n",
      "6366it [06:46, 13.88it/s]\u001b[A\n",
      "6372it [06:47, 10.89it/s]\u001b[A\n",
      "6385it [06:47, 12.06it/s]\u001b[A\n",
      "6401it [06:48, 13.94it/s]\u001b[A\n",
      "6417it [06:49, 15.52it/s]\u001b[A\n",
      "6433it [06:50, 15.68it/s]\u001b[A\n",
      "6444it [06:50, 20.12it/s]\u001b[A\n",
      "6449it [06:51, 14.86it/s]\u001b[A\n",
      "6465it [06:52, 15.90it/s]\u001b[A\n",
      "6481it [06:53, 15.84it/s]\u001b[A\n",
      "6492it [06:53, 20.38it/s]\u001b[A\n",
      "6498it [06:54, 15.47it/s]\u001b[A\n",
      "6507it [06:54, 19.78it/s]\u001b[A\n",
      "6513it [06:55, 14.59it/s]\u001b[A\n",
      "6529it [06:56, 15.63it/s]\u001b[A\n",
      "6542it [06:56, 22.16it/s]\u001b[A\n",
      "6549it [06:57, 16.17it/s]\u001b[A\n",
      "6561it [06:58, 15.01it/s]\u001b[A\n",
      "6577it [06:59, 15.90it/s]\u001b[A\n",
      "6592it [06:59, 22.91it/s]\u001b[A\n",
      "6599it [07:00, 17.23it/s]\u001b[A\n",
      "6609it [07:01, 14.75it/s]\u001b[A\n",
      "6625it [07:02, 15.74it/s]\u001b[A\n",
      "6641it [07:02, 16.37it/s]\u001b[A\n",
      "6657it [07:03, 16.30it/s]\u001b[A\n",
      "6671it [07:04, 22.03it/s]\u001b[A\n",
      "6677it [07:05, 14.37it/s]\u001b[A\n",
      "6686it [07:05, 18.04it/s]\u001b[A\n",
      "6692it [07:06, 13.27it/s]\u001b[A\n",
      "6705it [07:07, 13.27it/s]\u001b[A\n",
      "6719it [07:07, 19.74it/s]\u001b[A\n",
      "6726it [07:08, 15.27it/s]\u001b[A\n",
      "6737it [07:09, 14.22it/s]\u001b[A\n",
      "6753it [07:10, 15.51it/s]\u001b[A\n",
      "6769it [07:11, 14.54it/s]\u001b[A\n",
      "6775it [07:11, 16.44it/s]\u001b[A\n",
      "6783it [07:11, 20.07it/s]\u001b[A\n",
      "6788it [07:12, 13.59it/s]\u001b[A\n",
      "6801it [07:13, 13.67it/s]\u001b[A\n",
      "6816it [07:13, 21.23it/s]\u001b[A\n",
      "6823it [07:14, 15.03it/s]\u001b[A\n",
      "6833it [07:15, 12.43it/s]\u001b[A\n",
      "6846it [07:15, 18.31it/s]\u001b[A\n",
      "6853it [07:16, 13.34it/s]\u001b[A\n",
      "6865it [07:17, 13.18it/s]\u001b[A\n",
      "6881it [07:18, 14.37it/s]\u001b[A\n",
      "6897it [07:19, 14.75it/s]\u001b[A\n",
      "6912it [07:19, 20.87it/s]\u001b[A\n",
      "6919it [07:20, 15.52it/s]\u001b[A\n",
      "6929it [07:23,  9.15it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "6933it [07:23, 10.09it/s]\u001b[A\n",
      "6937it [07:23, 11.29it/s]\u001b[A\n",
      "6941it [07:23, 12.76it/s]\u001b[A\n",
      "6945it [07:24,  8.63it/s]\u001b[A\n",
      "6959it [07:24, 16.53it/s]\u001b[A\n",
      "6965it [07:25, 12.28it/s]\u001b[A\n",
      "6977it [07:26, 10.50it/s]\u001b[A\n",
      "6982it [07:26, 12.39it/s]\u001b[A\n",
      "6990it [07:27, 16.72it/s]\u001b[A\n",
      "6995it [07:28, 10.42it/s]\u001b[A\n",
      "7007it [07:28, 16.96it/s]\u001b[A\n",
      "7013it [07:29, 10.57it/s]\u001b[A\n",
      "7022it [07:29, 14.86it/s]\u001b[A\n",
      "7028it [07:30, 10.91it/s]\u001b[A\n",
      "7041it [07:31, 11.04it/s]\u001b[A\n",
      "7052it [07:31, 15.86it/s]\u001b[A\n",
      "7058it [07:32, 12.35it/s]\u001b[A\n",
      "7073it [07:33, 13.97it/s]\u001b[A\n",
      "7089it [07:34, 13.81it/s]\u001b[A\n",
      "7099it [07:35, 17.72it/s]\u001b[A\n",
      "7105it [07:35, 13.66it/s]\u001b[A\n",
      "7121it [07:36, 14.90it/s]\u001b[A\n",
      "7137it [07:37, 15.05it/s]\u001b[A\n",
      "7150it [07:38, 20.48it/s]\u001b[A\n",
      "7156it [07:39, 14.36it/s]\u001b[A\n",
      "7168it [07:39, 19.86it/s]\u001b[A\n",
      "7175it [07:40, 14.82it/s]\u001b[A\n",
      "7185it [07:41, 13.35it/s]\u001b[A\n",
      "7201it [07:42, 14.17it/s]\u001b[A\n",
      "7215it [07:42, 20.32it/s]\u001b[A\n",
      "7222it [07:43, 15.56it/s]\u001b[A\n",
      "7233it [07:44, 13.76it/s]\u001b[A\n",
      "7245it [07:44, 19.21it/s]\u001b[A\n",
      "7251it [07:45, 14.08it/s]\u001b[A\n",
      "7265it [07:46, 13.55it/s]\u001b[A\n",
      "7273it [07:46, 16.85it/s]\u001b[A\n",
      "7281it [07:47, 13.64it/s]\u001b[A\n",
      "7297it [07:48, 13.93it/s]\u001b[A\n",
      "7309it [07:48, 19.13it/s]\u001b[A\n",
      "7315it [07:49, 13.21it/s]\u001b[A\n",
      "7327it [07:49, 18.90it/s]\u001b[A\n",
      "7334it [07:50, 14.68it/s]\u001b[A\n",
      "7345it [07:51, 13.48it/s]\u001b[A\n",
      "7361it [07:52, 14.62it/s]\u001b[A\n",
      "7377it [07:53, 14.34it/s]\u001b[A\n",
      "7388it [07:53, 18.58it/s]\u001b[A\n",
      "7393it [07:54, 13.99it/s]\u001b[A\n",
      "7409it [07:55, 14.33it/s]\u001b[A\n",
      "7419it [07:55, 18.48it/s]\u001b[A\n",
      "7425it [07:56, 14.11it/s]\u001b[A\n",
      "7441it [07:57, 15.32it/s]\u001b[A\n",
      "7457it [07:58, 15.83it/s]\u001b[A\n",
      "7472it [07:58, 22.46it/s]\u001b[A\n",
      "7479it [07:59, 15.76it/s]\u001b[A\n",
      "7489it [08:00, 14.09it/s]\u001b[A\n",
      "7505it [08:01, 14.56it/s]\u001b[A\n",
      "7520it [08:01, 20.93it/s]\u001b[A\n",
      "7527it [08:02, 14.75it/s]\u001b[A\n",
      "7537it [08:03, 13.40it/s]\u001b[A\n",
      "7553it [08:04, 14.38it/s]\u001b[A\n",
      "7563it [08:04, 18.35it/s]\u001b[A\n",
      "7569it [08:05, 14.08it/s]\u001b[A\n",
      "7585it [08:06, 15.02it/s]\u001b[A\n",
      "7601it [08:07, 15.63it/s]\u001b[A\n",
      "7617it [08:08, 16.08it/s]\u001b[A\n",
      "7633it [08:09, 16.55it/s]\u001b[A\n",
      "7649it [08:10, 17.20it/s]\u001b[A\n",
      "7665it [08:11, 16.77it/s]\u001b[A\n",
      "7678it [08:11, 21.83it/s]\u001b[A\n",
      "7684it [08:12, 16.02it/s]\u001b[A\n",
      "7697it [08:13, 14.46it/s]\u001b[A\n",
      "7709it [08:13, 19.51it/s]\u001b[A\n",
      "7715it [08:14, 14.39it/s]\u001b[A\n",
      "7728it [08:14, 20.85it/s]\u001b[A\n",
      "7735it [08:15, 15.51it/s]\u001b[A\n",
      "7745it [08:16, 12.75it/s]\u001b[A\n",
      "7756it [08:16, 17.79it/s]\u001b[A\n",
      "7762it [08:17, 10.91it/s]\u001b[A\n",
      "7769it [08:18, 13.74it/s]\u001b[A\n",
      "7776it [08:18, 17.29it/s]\u001b[A\n",
      "7782it [08:19, 12.22it/s]\u001b[A\n",
      "7793it [08:19, 12.52it/s]\u001b[A\n",
      "7809it [08:20, 14.79it/s]\u001b[A\n",
      "7825it [08:21, 15.61it/s]\u001b[A\n",
      "7837it [08:21, 20.98it/s]\u001b[A\n",
      "7843it [08:22, 15.35it/s]\u001b[A\n",
      "7857it [08:23, 14.61it/s]\u001b[A\n",
      "7871it [08:23, 21.07it/s]\u001b[A\n",
      "7878it [08:24, 14.54it/s]\u001b[A\n",
      "7889it [08:25, 13.47it/s]\u001b[A\n",
      "7905it [08:26, 14.40it/s]\u001b[A\n",
      "7921it [08:29, 10.42it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "7925it [08:29, 11.28it/s]\u001b[A\n",
      "7929it [08:29, 12.38it/s]\u001b[A\n",
      "7933it [08:29, 13.75it/s]\u001b[A\n",
      "7937it [08:30,  9.69it/s]\u001b[A\n",
      "7953it [08:31, 12.55it/s]\u001b[A\n",
      "7969it [08:32, 13.80it/s]\u001b[A\n",
      "7984it [08:32, 20.60it/s]\u001b[A\n",
      "7990it [08:33, 15.28it/s]\u001b[A\n",
      "8001it [08:34, 14.17it/s]\u001b[A\n",
      "8017it [08:35, 14.20it/s]\u001b[A\n",
      "8029it [08:35, 19.14it/s]\u001b[A\n",
      "8035it [08:36, 13.78it/s]\u001b[A\n",
      "8049it [08:37, 14.01it/s]\u001b[A\n",
      "8064it [08:37, 20.75it/s]\u001b[A\n",
      "8071it [08:38, 15.83it/s]\u001b[A\n",
      "8081it [08:39, 13.47it/s]\u001b[A\n",
      "8093it [08:39, 18.92it/s]\u001b[A\n",
      "8099it [08:40, 14.10it/s]\u001b[A\n",
      "8113it [08:41, 13.91it/s]\u001b[A\n",
      "8125it [08:41, 19.42it/s]\u001b[A\n",
      "8132it [08:42, 15.21it/s]\u001b[A\n",
      "8145it [08:43, 15.12it/s]\u001b[A\n",
      "8161it [08:44, 14.90it/s]\u001b[A\n",
      "8172it [08:44, 19.51it/s]\u001b[A\n",
      "8178it [08:45, 14.01it/s]\u001b[A\n",
      "8192it [08:45, 20.96it/s]\u001b[A\n",
      "8199it [08:46, 15.23it/s]\u001b[A\n",
      "8209it [08:47, 13.71it/s]\u001b[A\n",
      "8225it [08:48, 15.03it/s]\u001b[A\n",
      "8241it [08:49, 14.48it/s]\u001b[A\n",
      "8252it [08:49, 18.73it/s]\u001b[A\n",
      "8257it [08:50, 14.00it/s]\u001b[A\n",
      "8273it [08:51, 15.05it/s]\u001b[A\n",
      "8288it [08:51, 21.93it/s]\u001b[A\n",
      "8295it [08:52, 16.35it/s]\u001b[A\n",
      "8305it [08:53, 13.04it/s]\u001b[A\n",
      "8315it [08:53, 17.29it/s]\u001b[A\n",
      "8321it [08:54, 12.73it/s]\u001b[A\n",
      "8335it [08:54, 19.85it/s]\u001b[A\n",
      "8342it [08:55, 14.16it/s]\u001b[A\n",
      "8353it [08:56, 13.37it/s]\u001b[A\n",
      "8369it [08:57, 14.75it/s]\u001b[A\n",
      "8380it [08:57, 19.54it/s]\u001b[A\n",
      "8386it [08:58, 14.85it/s]\u001b[A\n",
      "8401it [08:59, 15.31it/s]\u001b[A\n",
      "8416it [08:59, 22.62it/s]\u001b[A\n",
      "8423it [09:00, 17.00it/s]\u001b[A\n",
      "8433it [09:01, 14.46it/s]\u001b[A\n",
      "8447it [09:01, 21.39it/s]\u001b[A\n",
      "8454it [09:02, 15.68it/s]\u001b[A\n",
      "8465it [09:03, 14.37it/s]\u001b[A\n",
      "8481it [09:04, 14.84it/s]\u001b[A\n",
      "8495it [09:04, 21.01it/s]\u001b[A\n",
      "8502it [09:05, 15.97it/s]\u001b[A\n",
      "8513it [09:06, 14.20it/s]\u001b[A\n",
      "8529it [09:07, 14.95it/s]\u001b[A\n",
      "8545it [09:08, 15.28it/s]\u001b[A\n",
      "8558it [09:08, 20.56it/s]\u001b[A\n",
      "8564it [09:09, 15.51it/s]\u001b[A\n",
      "8577it [09:10, 14.82it/s]\u001b[A\n",
      "8591it [09:10, 21.26it/s]\u001b[A\n",
      "8598it [09:11, 16.34it/s]\u001b[A\n",
      "8609it [09:12, 15.04it/s]\u001b[A\n",
      "8625it [09:13, 14.79it/s]\u001b[A\n",
      "8637it [09:13, 19.84it/s]\u001b[A\n",
      "8643it [09:14, 15.25it/s]\u001b[A\n",
      "8657it [09:15, 14.54it/s]\u001b[A\n",
      "8667it [09:15, 18.88it/s]\u001b[A\n",
      "8673it [09:16, 14.17it/s]\u001b[A\n",
      "8689it [09:17, 14.28it/s]\u001b[A\n",
      "8701it [09:17, 19.58it/s]\u001b[A\n",
      "8707it [09:18, 15.02it/s]\u001b[A\n",
      "8721it [09:19, 15.18it/s]\u001b[A\n",
      "8737it [09:20, 14.79it/s]\u001b[A\n",
      "8747it [09:20, 18.79it/s]\u001b[A\n",
      "8753it [09:21, 14.15it/s]\u001b[A\n",
      "8769it [09:22, 14.55it/s]\u001b[A\n",
      "8785it [09:23, 15.00it/s]\u001b[A\n",
      "8800it [09:23, 21.31it/s]\u001b[A\n",
      "8807it [09:24, 15.27it/s]\u001b[A\n",
      "8817it [09:25, 13.32it/s]\u001b[A\n",
      "8832it [09:25, 19.91it/s]\u001b[A\n",
      "8839it [09:26, 14.94it/s]\u001b[A\n",
      "8849it [09:27, 12.06it/s]\u001b[A\n",
      "8858it [09:27, 15.68it/s]\u001b[A\n",
      "8865it [09:28, 12.20it/s]\u001b[A\n",
      "8878it [09:29, 18.57it/s]\u001b[A\n",
      "8885it [09:29, 13.98it/s]\u001b[A\n",
      "8897it [09:30, 13.13it/s]\u001b[A\n",
      "8909it [09:31, 18.77it/s]\u001b[A\n",
      "8916it [09:31, 14.22it/s]\u001b[A\n",
      "8927it [09:32, 19.91it/s]\u001b[A\n",
      "8934it [09:32, 14.96it/s]\u001b[A\n",
      "8945it [09:33, 13.75it/s]\u001b[A\n",
      "8961it [09:34, 15.11it/s]\u001b[A\n",
      "8977it [09:35, 15.06it/s]\u001b[A\n",
      "8989it [09:35, 20.05it/s]\u001b[A\n",
      "8995it [09:36, 15.11it/s]\u001b[A\n",
      "9009it [09:37, 15.28it/s]\u001b[A\n",
      "9025it [09:38, 15.38it/s]\u001b[A\n",
      "9039it [09:38, 21.36it/s]\u001b[A\n",
      "9045it [09:39, 15.51it/s]\u001b[A\n",
      "9057it [09:40, 14.41it/s]\u001b[A\n",
      "9073it [09:41, 14.91it/s]\u001b[A\n",
      "9089it [09:43, 13.61it/s]\u001b[A\n",
      "9097it [09:43, 16.22it/s]\u001b[A\n",
      "9105it [09:44, 13.47it/s]\u001b[A\n",
      "9121it [09:45, 14.65it/s]\u001b[A\n",
      "9137it [09:46, 15.31it/s]\u001b[A\n",
      "9152it [09:46, 21.53it/s]\u001b[A\n",
      "9158it [09:47, 16.13it/s]\u001b[A\n",
      "9169it [09:48, 14.54it/s]\u001b[A\n",
      "9180it [09:48, 19.44it/s]\u001b[A\n",
      "9186it [09:48, 14.65it/s]\u001b[A\n",
      "9201it [09:49, 14.91it/s]\u001b[A\n",
      "9217it [09:50, 15.51it/s]\u001b[A\n",
      "9233it [09:51, 16.06it/s]\u001b[A\n",
      "9249it [09:52, 16.50it/s]\u001b[A\n",
      "9265it [09:53, 16.89it/s]\u001b[A\n",
      "9281it [09:54, 15.76it/s]\u001b[A\n",
      "9291it [09:54, 19.26it/s]\u001b[A\n",
      "9297it [09:55, 14.77it/s]\u001b[A\n",
      "9312it [09:55, 21.91it/s]\u001b[A\n",
      "9319it [09:56, 16.09it/s]\u001b[A\n",
      "9329it [09:57, 13.62it/s]\u001b[A\n",
      "9342it [09:57, 19.68it/s]\u001b[A\n",
      "9349it [09:58, 14.13it/s]\u001b[A\n",
      "9361it [10:00, 12.57it/s]\u001b[A\n",
      "9372it [10:00, 17.24it/s]\u001b[A\n",
      "9378it [10:01, 12.43it/s]\u001b[A\n",
      "9390it [10:01, 18.24it/s]\u001b[A\n",
      "9397it [10:02, 13.15it/s]\u001b[A\n",
      "9409it [10:03, 12.25it/s]\u001b[A\n",
      "9420it [10:03, 17.10it/s]\u001b[A\n",
      "9426it [10:04, 12.38it/s]\u001b[A\n",
      "9435it [10:04, 16.64it/s]\u001b[A\n",
      "9441it [10:05, 12.53it/s]\u001b[A\n",
      "9457it [10:06, 13.36it/s]\u001b[A\n",
      "9468it [10:06, 18.31it/s]\u001b[A\n",
      "9474it [10:08, 11.89it/s]\u001b[A\n",
      "9482it [10:08, 15.45it/s]\u001b[A\n",
      "9489it [10:09, 12.29it/s]\u001b[A\n",
      "9505it [10:10, 12.84it/s]\u001b[A\n",
      "9516it [10:10, 17.55it/s]\u001b[A\n",
      "9522it [10:11, 12.22it/s]\u001b[A\n",
      "9534it [10:11, 17.88it/s]\u001b[A\n",
      "9540it [10:12, 12.78it/s]\u001b[A\n",
      "9553it [10:13, 13.33it/s]\u001b[A\n",
      "9569it [10:14, 13.90it/s]\u001b[A\n",
      "9580it [10:14, 18.44it/s]\u001b[A\n",
      "9586it [10:15, 13.93it/s]\u001b[A\n",
      "9601it [10:16, 14.91it/s]\u001b[A\n",
      "9617it [10:17, 14.75it/s]\u001b[A\n",
      "9628it [10:17, 19.20it/s]\u001b[A\n",
      "9634it [10:18, 13.61it/s]\u001b[A\n",
      "9647it [10:18, 19.78it/s]\u001b[A\n",
      "9654it [10:19, 14.16it/s]\u001b[A\n",
      "9665it [10:20, 13.14it/s]\u001b[A\n",
      "9681it [10:21, 14.68it/s]\u001b[A\n",
      "9697it [10:23, 13.62it/s]\u001b[A\n",
      "9705it [10:23, 16.39it/s]\u001b[A\n",
      "9713it [10:24, 13.09it/s]\u001b[A\n",
      "9726it [10:24, 18.93it/s]\u001b[A\n",
      "9732it [10:25, 13.91it/s]\u001b[A\n",
      "9745it [10:26, 13.91it/s]\u001b[A\n",
      "9761it [10:27, 15.26it/s]\u001b[A\n",
      "9777it [10:28, 15.61it/s]\u001b[A\n",
      "9791it [10:28, 21.51it/s]\u001b[A\n",
      "9797it [10:29, 15.73it/s]\u001b[A\n",
      "9809it [10:30, 14.12it/s]\u001b[A\n",
      "9822it [10:30, 19.89it/s]\u001b[A\n",
      "9829it [10:31, 14.28it/s]\u001b[A\n",
      "9841it [10:32, 12.84it/s]\u001b[A\n",
      "9852it [10:32, 17.48it/s]\u001b[A\n",
      "9858it [10:33, 13.47it/s]\u001b[A\n",
      "9873it [10:34, 14.44it/s]\u001b[A\n",
      "9889it [10:35, 15.26it/s]\u001b[A\n",
      "9904it [10:35, 21.91it/s]\u001b[A\n",
      "9911it [10:36, 14.94it/s]\u001b[A\n",
      "9921it [10:37, 12.79it/s]\u001b[A\n",
      "9932it [10:37, 17.37it/s]\u001b[A\n",
      "9938it [10:38, 13.34it/s]\u001b[A\n",
      "9953it [10:39, 13.85it/s]\u001b[A\n",
      "9967it [10:39, 20.23it/s]\u001b[A\n",
      "9974it [10:40, 14.22it/s]\u001b[A\n",
      "9985it [10:41, 13.12it/s]\u001b[A\n",
      "10001it [10:42, 13.88it/s]\u001b[A\n",
      "10015it [10:42, 19.67it/s]\u001b[A\n",
      "10022it [10:43, 15.22it/s]\u001b[A\n",
      "10033it [10:44, 14.26it/s]\u001b[A\n",
      "10049it [10:45, 14.98it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "10063it [10:45, 21.02it/s]\u001b[A\n",
      "10070it [10:46, 16.40it/s]\u001b[A\n",
      "10081it [10:47, 15.32it/s]\u001b[A\n",
      "10097it [10:48, 15.60it/s]\u001b[A\n",
      "10112it [10:48, 22.34it/s]\u001b[A\n",
      "10119it [10:49, 14.31it/s]\u001b[A\n",
      "10128it [10:49, 18.09it/s]\u001b[A\n",
      "10134it [10:51, 11.17it/s]\u001b[A\n",
      "10142it [10:51, 14.45it/s]\u001b[A\n",
      "10148it [10:52, 10.55it/s]\u001b[A\n",
      "10160it [10:52, 16.31it/s]\u001b[A\n",
      "10166it [10:53, 12.42it/s]\u001b[A\n",
      "10177it [10:54, 12.35it/s]\u001b[A\n",
      "10193it [10:55, 13.49it/s]\u001b[A\n",
      "10205it [10:55, 18.71it/s]\u001b[A\n",
      "10211it [10:56, 14.31it/s]\u001b[A\n",
      "10225it [10:57, 14.97it/s]\u001b[A\n",
      "10241it [10:58, 15.96it/s]\u001b[A\n",
      "10257it [10:59, 16.35it/s]\u001b[A\n",
      "10273it [11:00, 16.45it/s]\u001b[A\n",
      "10289it [11:01, 15.80it/s]\u001b[A\n",
      "10302it [11:01, 20.74it/s]\u001b[A\n",
      "10308it [11:02, 15.01it/s]\u001b[A\n",
      "10321it [11:03, 14.17it/s]\u001b[A\n",
      "10335it [11:03, 20.14it/s]\u001b[A\n",
      "10342it [11:04, 15.82it/s]\u001b[A\n",
      "10353it [11:05, 14.52it/s]\u001b[A\n",
      "10369it [11:06, 15.08it/s]\u001b[A\n",
      "10383it [11:06, 21.21it/s]\u001b[A\n",
      "10390it [11:07, 15.96it/s]\u001b[A\n",
      "10401it [11:08, 13.54it/s]\u001b[A\n",
      "10409it [11:08, 16.77it/s]\u001b[A\n",
      "10417it [11:09, 13.10it/s]\u001b[A\n",
      "10431it [11:09, 20.13it/s]\u001b[A\n",
      "10438it [11:10, 13.23it/s]\u001b[A\n",
      "10447it [11:10, 17.39it/s]\u001b[A\n",
      "10453it [11:11, 12.59it/s]\u001b[A\n",
      "10465it [11:12, 11.78it/s]\u001b[A\n",
      "10478it [11:12, 17.72it/s]\u001b[A\n",
      "10485it [11:14, 12.45it/s]\u001b[A\n",
      "10495it [11:14, 17.10it/s]\u001b[A\n",
      "10502it [11:15, 13.40it/s]\u001b[A\n",
      "10513it [11:15, 13.17it/s]\u001b[A\n",
      "10529it [11:16, 14.78it/s]\u001b[A\n",
      "10545it [11:17, 15.52it/s]\u001b[A\n",
      "10561it [11:18, 15.67it/s]\u001b[A\n",
      "10576it [11:18, 21.90it/s]\u001b[A\n",
      "10583it [11:19, 16.13it/s]\u001b[A\n",
      "10593it [11:20, 14.07it/s]\u001b[A\n",
      "10609it [11:21, 14.55it/s]\u001b[A\n",
      "10625it [11:23, 13.73it/s]\u001b[A\n",
      "10635it [11:23, 17.20it/s]\u001b[A\n",
      "10641it [11:24, 13.26it/s]\u001b[A\n",
      "10657it [11:25, 13.97it/s]\u001b[A\n",
      "10671it [11:25, 19.84it/s]\u001b[A\n",
      "10678it [11:26, 15.79it/s]\u001b[A\n",
      "10689it [11:27, 12.83it/s]\u001b[A\n",
      "10699it [11:27, 16.92it/s]\u001b[A\n",
      "10705it [11:28, 12.27it/s]\u001b[A\n",
      "10721it [11:29, 13.30it/s]\u001b[A\n",
      "10735it [11:29, 19.36it/s]\u001b[A\n",
      "10742it [11:30, 14.40it/s]\u001b[A\n",
      "10753it [11:31, 13.40it/s]\u001b[A\n",
      "10769it [11:32, 14.45it/s]\u001b[A\n",
      "10785it [11:33, 14.39it/s]\u001b[A\n",
      "10795it [11:33, 18.15it/s]\u001b[A\n",
      "10801it [11:34, 13.76it/s]\u001b[A\n",
      "10817it [11:35, 14.95it/s]\u001b[A\n",
      "10833it [11:36, 15.01it/s]\u001b[A\n",
      "10848it [11:36, 21.19it/s]\u001b[A\n",
      "10855it [11:38, 15.34it/s]\u001b[A\n",
      "10865it [11:38, 13.74it/s]\u001b[A\n",
      "10881it [11:39, 14.79it/s]\u001b[A\n",
      "10897it [11:40, 15.40it/s]\u001b[A\n",
      "10913it [11:41, 15.84it/s]\u001b[A\n",
      "10929it [11:42, 15.73it/s]\u001b[A\n",
      "10943it [11:42, 21.08it/s]\u001b[A\n",
      "10949it [11:43, 15.27it/s]\u001b[A\n",
      "10961it [11:44, 14.55it/s]\u001b[A\n",
      "10977it [11:45, 14.61it/s]\u001b[A\n",
      "10990it [11:46, 19.79it/s]\u001b[A\n",
      "10996it [11:47, 14.35it/s]\u001b[A\n",
      "11009it [11:48, 13.49it/s]\u001b[A\n",
      "11021it [11:48, 18.55it/s]\u001b[A\n",
      "11027it [11:49, 14.30it/s]\u001b[A\n",
      "11041it [11:50, 13.96it/s]\u001b[A\n",
      "11053it [11:50, 19.33it/s]\u001b[A\n",
      "11059it [11:51, 14.64it/s]\u001b[A\n",
      "11073it [11:52, 14.88it/s]\u001b[A\n",
      "11089it [11:53, 15.22it/s]\u001b[A\n",
      "11103it [11:53, 21.38it/s]\u001b[A\n",
      "11110it [11:53, 16.43it/s]\u001b[A\n",
      "11121it [11:54, 15.03it/s]\u001b[A\n",
      "11137it [11:56, 14.34it/s]\u001b[A\n",
      "11147it [11:56, 18.29it/s]\u001b[A\n",
      "11153it [11:57, 12.60it/s]\u001b[A\n",
      "11163it [11:57, 16.98it/s]\u001b[A\n",
      "11169it [11:58, 12.05it/s]\u001b[A\n",
      "11181it [11:58, 17.93it/s]\u001b[A\n",
      "11188it [11:59, 13.34it/s]\u001b[A\n",
      "11201it [12:00, 12.51it/s]\u001b[A\n",
      "11214it [12:00, 18.34it/s]\u001b[A\n",
      "11221it [12:01, 13.45it/s]\u001b[A\n",
      "11233it [12:02, 12.61it/s]\u001b[A\n",
      "11244it [12:03, 17.37it/s]\u001b[A\n",
      "11250it [12:04, 11.78it/s]\u001b[A\n",
      "11260it [12:04, 16.29it/s]\u001b[A\n",
      "11266it [12:05, 12.63it/s]\u001b[A\n",
      "11281it [12:06, 14.30it/s]\u001b[A\n",
      "11297it [12:06, 15.26it/s]\u001b[A\n",
      "11313it [12:07, 15.81it/s]\u001b[A\n",
      "11329it [12:08, 15.69it/s]\u001b[A\n",
      "11342it [12:09, 20.83it/s]\u001b[A\n",
      "11348it [12:09, 15.65it/s]\u001b[A\n",
      "11360it [12:10, 21.38it/s]\u001b[A\n",
      "11367it [12:11, 15.42it/s]\u001b[A\n",
      "11377it [12:12, 13.04it/s]\u001b[A\n",
      "11390it [12:12, 19.10it/s]\u001b[A\n",
      "11397it [12:13, 14.88it/s]\u001b[A\n",
      "11409it [12:14, 13.77it/s]\u001b[A\n",
      "11424it [12:14, 20.98it/s]\u001b[A\n",
      "11431it [12:14, 15.99it/s]\u001b[A\n",
      "11441it [12:15, 14.94it/s]\u001b[A\n",
      "11457it [12:16, 15.04it/s]\u001b[A\n",
      "11468it [12:16, 19.87it/s]\u001b[A\n",
      "11474it [12:17, 14.76it/s]\u001b[A\n",
      "11489it [12:18, 13.80it/s]\u001b[A\n",
      "11500it [12:19, 18.42it/s]\u001b[A\n",
      "11506it [12:20, 13.62it/s]\u001b[A\n",
      "11521it [12:21, 14.23it/s]\u001b[A\n",
      "11536it [12:21, 21.09it/s]\u001b[A\n",
      "11543it [12:22, 14.91it/s]\u001b[A\n",
      "11553it [12:23, 12.69it/s]\u001b[A\n",
      "11562it [12:23, 16.42it/s]\u001b[A\n",
      "11569it [12:24, 13.08it/s]\u001b[A\n",
      "11585it [12:25, 14.02it/s]\u001b[A\n",
      "11598it [12:25, 19.89it/s]\u001b[A\n",
      "11604it [12:26, 14.78it/s]\u001b[A\n",
      "11617it [12:27, 14.54it/s]\u001b[A\n",
      "11633it [12:28, 14.06it/s]\u001b[A\n",
      "11642it [12:28, 17.56it/s]\u001b[A\n",
      "11649it [12:29, 13.52it/s]\u001b[A\n",
      "11663it [12:29, 20.34it/s]\u001b[A\n",
      "11670it [12:30, 14.30it/s]\u001b[A\n",
      "11681it [12:31, 13.11it/s]\u001b[A\n",
      "11696it [12:31, 20.19it/s]\u001b[A\n",
      "11703it [12:32, 14.95it/s]\u001b[A\n",
      "11713it [12:33, 12.85it/s]\u001b[A\n",
      "11727it [12:33, 19.31it/s]\u001b[A\n",
      "11734it [12:34, 14.48it/s]\u001b[A\n",
      "11745it [12:35, 13.15it/s]\u001b[A\n",
      "11761it [12:36, 14.40it/s]\u001b[A\n",
      "11777it [12:37, 14.62it/s]\u001b[A\n",
      "11784it [12:37, 17.06it/s]\u001b[A\n",
      "11793it [12:38, 13.40it/s]\u001b[A\n",
      "11807it [12:39, 19.82it/s]\u001b[A\n",
      "11813it [12:40, 13.88it/s]\u001b[A\n",
      "11825it [12:41, 12.98it/s]\u001b[A\n",
      "11841it [12:42, 12.82it/s]\u001b[A\n",
      "11851it [12:42, 16.58it/s]\u001b[A\n",
      "11857it [12:43, 11.74it/s]\u001b[A\n",
      "11869it [12:43, 16.92it/s]\u001b[A\n",
      "11875it [12:44, 11.92it/s]\u001b[A\n",
      "11888it [12:44, 18.08it/s]\u001b[A\n",
      "11895it [12:45, 13.70it/s]\u001b[A\n",
      "11905it [12:46, 13.04it/s]\u001b[A\n",
      "11921it [12:47, 14.55it/s]\u001b[A\n",
      "11937it [12:48, 14.99it/s]\u001b[A\n",
      "11950it [12:48, 20.42it/s]\u001b[A\n",
      "11956it [12:49, 15.60it/s]\u001b[A\n",
      "11969it [12:50, 15.03it/s]\u001b[A\n",
      "11985it [12:51, 14.81it/s]\u001b[A\n",
      "11995it [12:51, 18.80it/s]\u001b[A\n",
      "12001it [12:52, 14.18it/s]\u001b[A\n",
      "12017it [12:54, 13.30it/s]\u001b[A\n",
      "12026it [12:54, 16.73it/s]\u001b[A\n",
      "12033it [12:55, 12.96it/s]\u001b[A\n",
      "12048it [12:55, 20.23it/s]\u001b[A\n",
      "12055it [12:56, 15.60it/s]\u001b[A\n",
      "12065it [12:57, 12.30it/s]\u001b[A\n",
      "12073it [12:57, 15.66it/s]\u001b[A\n",
      "12081it [12:58, 13.04it/s]\u001b[A\n",
      "12097it [12:59, 14.33it/s]\u001b[A\n",
      "12111it [12:59, 20.90it/s]\u001b[A\n",
      "12118it [13:00, 16.40it/s]\u001b[A\n",
      "12129it [13:00, 15.08it/s]\u001b[A\n",
      "12145it [13:01, 15.84it/s]\u001b[A\n",
      "12161it [13:02, 15.97it/s]\u001b[A\n",
      "12177it [13:04, 15.30it/s]\u001b[A\n",
      "12188it [13:04, 19.49it/s]\u001b[A\n",
      "12193it [13:05, 14.39it/s]\u001b[A\n",
      "12209it [13:06, 14.49it/s]\u001b[A\n",
      "12220it [13:06, 18.99it/s]\u001b[A\n",
      "12226it [13:07, 14.32it/s]\u001b[A\n",
      "12241it [13:08, 15.17it/s]\u001b[A\n",
      "12257it [13:08, 15.93it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "12273it [13:10, 15.63it/s]\u001b[A\n",
      "12286it [13:10, 20.87it/s]\u001b[A\n",
      "12292it [13:11, 15.30it/s]\u001b[A\n",
      "12305it [13:12, 14.26it/s]\u001b[A\n",
      "12319it [13:12, 20.39it/s]\u001b[A\n",
      "12326it [13:13, 15.03it/s]\u001b[A\n",
      "12337it [13:14, 13.34it/s]\u001b[A\n",
      "12351it [13:14, 19.60it/s]\u001b[A\n",
      "12358it [13:15, 12.88it/s]\u001b[A\n",
      "12368it [13:15, 17.23it/s]\u001b[A\n",
      "12375it [13:16, 13.56it/s]\u001b[A\n",
      "12385it [13:17, 11.95it/s]\u001b[A\n",
      "12398it [13:17, 17.91it/s]\u001b[A\n",
      "12405it [13:18, 13.90it/s]\u001b[A\n",
      "12417it [13:19, 13.53it/s]\u001b[A\n",
      "12432it [13:19, 20.82it/s]\u001b[A\n",
      "12439it [13:20, 14.11it/s]\u001b[A\n",
      "12449it [13:21, 12.62it/s]\u001b[A\n",
      "12465it [13:22, 13.87it/s]\u001b[A\n",
      "12481it [13:23, 14.55it/s]\u001b[A\n",
      "12497it [13:24, 14.84it/s]\u001b[A\n",
      "12510it [13:24, 19.84it/s]\u001b[A\n",
      "12516it [13:26, 13.81it/s]\u001b[A\n",
      "12526it [13:26, 18.03it/s]\u001b[A\n",
      "12532it [13:27, 14.08it/s]\u001b[A\n",
      "12545it [13:27, 13.92it/s]\u001b[A\n",
      "12559it [13:28, 20.65it/s]\u001b[A\n",
      "12566it [13:28, 15.25it/s]\u001b[A\n",
      "12577it [13:29, 14.14it/s]\u001b[A\n",
      "12593it [13:32,  9.76it/s]\u001b[A\n",
      "12597it [13:32, 10.67it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "12601it [13:32, 11.85it/s]\u001b[A\n",
      "12605it [13:32, 13.30it/s]\u001b[A\n",
      "12609it [13:33,  8.90it/s]\u001b[A\n",
      "12623it [13:33, 16.76it/s]\u001b[A\n",
      "12629it [13:34, 12.33it/s]\u001b[A\n",
      "12641it [13:35, 12.26it/s]\u001b[A\n",
      "12655it [13:35, 19.31it/s]\u001b[A\n",
      "12662it [13:36, 14.39it/s]\u001b[A\n",
      "12673it [13:37, 13.98it/s]\u001b[A\n",
      "12689it [13:38, 15.24it/s]\u001b[A\n",
      "12705it [13:39, 16.01it/s]\u001b[A\n",
      "12721it [13:40, 16.70it/s]\u001b[A\n",
      "12737it [13:41, 15.99it/s]\u001b[A\n",
      "12749it [13:41, 20.65it/s]\u001b[A\n",
      "12755it [13:42, 15.17it/s]\u001b[A\n",
      "12769it [13:43, 14.69it/s]\u001b[A\n",
      "12784it [13:43, 21.31it/s]\u001b[A\n",
      "12791it [13:44, 15.99it/s]\u001b[A\n",
      "12801it [13:45, 13.91it/s]\u001b[A\n",
      "12816it [13:45, 20.96it/s]\u001b[A\n",
      "12823it [13:46, 14.78it/s]\u001b[A\n",
      "12833it [13:47, 13.44it/s]\u001b[A\n",
      "12849it [13:48, 14.59it/s]\u001b[A\n",
      "12865it [13:49, 15.50it/s]\u001b[A\n",
      "12881it [13:50, 16.08it/s]\u001b[A\n",
      "12897it [13:51, 16.12it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "12909it [13:51, 20.75it/s]\u001b[A\n",
      "12915it [13:52, 14.57it/s]\u001b[A\n",
      "12927it [13:52, 19.98it/s]\u001b[A\n",
      "12934it [13:53, 14.90it/s]\u001b[A\n",
      "12945it [13:54, 13.54it/s]\u001b[A\n",
      "12961it [13:55, 13.88it/s]\u001b[A\n",
      "12969it [13:55, 16.90it/s]\u001b[A\n",
      "12977it [13:56, 13.85it/s]\u001b[A\n",
      "12993it [13:57, 14.99it/s]\u001b[A\n",
      "13009it [13:58, 14.57it/s]\u001b[A\n",
      "13019it [13:58, 18.38it/s]\u001b[A\n",
      "13025it [13:59, 13.71it/s]\u001b[A\n",
      "13040it [13:59, 21.04it/s]\u001b[A\n",
      "13047it [14:00, 15.76it/s]\u001b[A\n",
      "13057it [14:01, 13.64it/s]\u001b[A\n",
      "13070it [14:01, 19.95it/s]\u001b[A\n",
      "13077it [14:02, 14.68it/s]\u001b[A\n",
      "13089it [14:03, 13.34it/s]\u001b[A\n",
      "13101it [14:03, 18.84it/s]\u001b[A\n",
      "13108it [14:04, 14.02it/s]\u001b[A\n",
      "13121it [14:05, 13.04it/s]\u001b[A\n",
      "13132it [14:06, 17.81it/s]\u001b[A\n",
      "13138it [14:06, 13.25it/s]\u001b[A\n",
      "13153it [14:08, 13.86it/s]\u001b[A\n",
      "13163it [14:08, 18.24it/s]\u001b[A\n",
      "13169it [14:09, 12.84it/s]\u001b[A\n",
      "13180it [14:09, 18.22it/s]\u001b[A\n",
      "13186it [14:10, 12.55it/s]\u001b[A\n",
      "13197it [14:10, 18.22it/s]\u001b[A\n",
      "13204it [14:11, 14.18it/s]\u001b[A\n",
      "13217it [14:12, 14.01it/s]\u001b[A\n",
      "13231it [14:12, 21.15it/s]\u001b[A\n",
      "13238it [14:13, 15.48it/s]\u001b[A\n",
      "13249it [14:14, 13.92it/s]\u001b[A\n",
      "13264it [14:14, 21.40it/s]\u001b[A\n",
      "13272it [14:15, 14.58it/s]\u001b[A\n",
      "13281it [14:16, 12.65it/s]\u001b[A\n",
      "13297it [14:17, 12.51it/s]\u001b[A\n",
      "13306it [14:17, 15.79it/s]\u001b[A\n",
      "13313it [14:20,  8.36it/s]\u001b[A\n",
      "13317it [14:20,  9.38it/s]\u001b[A\n",
      "13321it [14:20, 10.57it/s]\u001b[A\n",
      "13325it [14:20, 12.18it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "13329it [14:21,  7.90it/s]\u001b[A\n",
      "13340it [14:21, 13.86it/s]\u001b[A\n",
      "13345it [14:22, 10.62it/s]\u001b[A\n",
      "13361it [14:23, 12.80it/s]\u001b[A\n",
      "13376it [14:23, 20.41it/s]\u001b[A\n",
      "13383it [14:24, 13.15it/s]\u001b[A\n",
      "13393it [14:25, 12.40it/s]\u001b[A\n",
      "13409it [14:26, 13.71it/s]\u001b[A\n",
      "13424it [14:26, 20.22it/s]\u001b[A\n",
      "13431it [14:27, 15.16it/s]\u001b[A\n",
      "13441it [14:28, 13.91it/s]\u001b[A\n",
      "13457it [14:29, 14.71it/s]\u001b[A\n",
      "13471it [14:29, 20.78it/s]\u001b[A\n",
      "13478it [14:30, 15.59it/s]\u001b[A\n",
      "13489it [14:31, 14.07it/s]\u001b[A\n",
      "13500it [14:31, 19.04it/s]\u001b[A\n",
      "13506it [14:32, 14.17it/s]\u001b[A\n",
      "13521it [14:33, 15.06it/s]\u001b[A\n",
      "13537it [14:34, 15.99it/s]\u001b[A\n",
      "13553it [14:36, 11.05it/s]\u001b[A\n",
      "13557it [14:36, 11.90it/s]\u001b[A\n",
      "13561it [14:37, 13.00it/s]\u001b[AWhisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "\n",
      "13565it [14:37, 14.38it/s]\u001b[A\n",
      "13569it [14:38,  9.20it/s]\u001b[A\n",
      "13579it [14:38, 14.46it/s]\u001b[A\n",
      "13585it [14:39, 11.13it/s]\u001b[A\n",
      "13601it [14:40, 13.38it/s]\u001b[A\n",
      "13617it [14:41, 14.28it/s]\u001b[A\n",
      "13633it [14:42, 14.32it/s]\u001b[A\n",
      "13645it [14:42, 19.11it/s]\u001b[A\n",
      "13651it [14:43, 14.19it/s]\u001b[A\n",
      "13665it [14:44, 12.83it/s]\u001b[A\n",
      "13674it [14:44, 16.27it/s]\u001b[A\n",
      "13681it [14:45, 13.26it/s]\u001b[A\n",
      "13697it [14:46, 14.86it/s]\u001b[A\n",
      "13713it [14:47, 15.83it/s]\u001b[A\n",
      "13729it [14:48, 15.91it/s]\u001b[A\n",
      "13741it [14:48, 20.77it/s]\u001b[A\n",
      "13747it [14:49, 14.75it/s]\u001b[A\n",
      "13761it [14:50, 14.46it/s]\u001b[A\n",
      "13776it [14:50, 21.08it/s]\u001b[A\n",
      "13783it [14:51, 15.51it/s]\u001b[A\n",
      "13793it [14:52, 13.96it/s]\u001b[A\n",
      "13809it [14:53, 15.10it/s]\u001b[A\n",
      "13825it [14:54, 16.02it/s]\u001b[A\n",
      "13842it [14:54, 15.47it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for out in tqdm(pipe(KeyDataset(test, 'audio'), generate_kwargs={\"language\": \"russian\"})):\n",
    "    predictions.append(out['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fb9ee55e-e479-41a2-a541-201b75116c21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.618"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wer = wer_metric.compute(references=test['transcription'], predictions=predictions)\n",
    "round(wer, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fc195adb-d36f-4781-a957-ff3073f35330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.382"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_accuracy = 1 - wer\n",
    "round(w_accuracy, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a152290b-5631-4c06-b7b3-6093a4650292",
   "metadata": {},
   "source": [
    "С увеличением объема данных тестовой выборки получили результат в $W_{\\text{accuracy}}\\approx38,2\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b364172e-e1e5-4b29-8aa5-0a5efa1f8738",
   "metadata": {},
   "source": [
    "# Дообучим модель (fine-tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9f15ee-01d4-45f0-901c-88d9abcae9ed",
   "metadata": {},
   "source": [
    "Для повышения качества модели дообучим её на данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b807acbf-7361-46f9-ada8-fb0605b2895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571c31d1-4ce1-47e8-a2ca-505999390e43",
   "metadata": {},
   "source": [
    "`pipeline` можно декомпозировать в 3 основные стадии:\n",
    "1. `feature extractor` - предобрабатывает входные аудио файлы и превращает их в log-mel спектрограммы\n",
    "2. Модель, которая выполняет вычисления\n",
    "3. `tokenizer` - предобрабатывает токены в текст\n",
    "\n",
    "В фреймворке `transformers`, whisper модель предоставляет и `WhisperFeatureExtractor`, и `WhisperTokenizer`. А также предоставляет класс `WhisperProcessor`, который объединяет эти два класса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05440928-9fee-407f-93f4-73e05860fae7",
   "metadata": {},
   "source": [
    "У наших данных sampling_rate уже установлен на 16kHz, ничего изменять не нужно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f1a5e6b-3465-4cd7-b9e7-abe95d2ffa0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': Audio(sampling_rate=16000, mono=True, decode=True, id=None),\n",
       " 'transcription': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ace2ae-0e44-44e7-9cf9-2f5cd6203aaa",
   "metadata": {},
   "source": [
    "При создании процессора, указываем язык и задачу (перевод или распознование текста)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecd14570-a0b1-4d57-b8b8-4cbb043adfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"russian\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f57eb1-bb0f-480b-b145-2f34ae37c26a",
   "metadata": {},
   "source": [
    "## Предобработка данных для дообучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82df1d1d-0227-4dba-96a0-1c7538d7b94f",
   "metadata": {},
   "source": [
    "1. Загружаем и повторно обрабатываем аудиоданные на основе выборки за выборкой, вызывая sample[\"audio\"].\n",
    "2. Ипользуем `feature extractor` для вычисления входных характеристик log-mel спектрограммы из нашего `array`.\n",
    "3. Кодируем транскрипции в идентификаторы меток с помощью `tokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb288fd6-9a0e-43a8-aca3-8e37db5eb7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(example):\n",
    "    audio = example[\"audio\"]\n",
    "\n",
    "    example = processor(\n",
    "        audio=audio[\"array\"],\n",
    "        sampling_rate=audio[\"sampling_rate\"],\n",
    "        text=example[\"transcription\"],\n",
    "    )\n",
    "\n",
    "    # compute input length of audio sample in seconds\n",
    "    example[\"input_length\"] = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e622e934-89c7-40e8-9631-2ad58638ee9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68982ed2bc8c45bf8b5690f06d94ee52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/32296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_processed = train.map(prepare_dataset, remove_columns=train.column_names, num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9db6cdc-f09d-473e-9586-555af9372b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dec94d77dad4d608e7ee1e7f7e6e84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13842 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_processed = test.map(prepare_dataset, remove_columns=test.column_names, num_proc=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a7509f-4aff-4c2b-bb65-e67ae5f214de",
   "metadata": {},
   "source": [
    "## Обучение\n",
    "HuggingFace Trainer большую часть работы уже реализована, нам нужно:\n",
    "\n",
    "* Выбрать средство сортировки данных (Data Collator): оно выбирает предобработанные данные и подготавливает их для PyTorch\n",
    "* Выбрать оценку (будем использовать WER)\n",
    "* Загрузить предобученную модель, настроить её на обучение\n",
    "* Определить аргументы для обучения. Они будут использоваться в `HuggingFace Trainer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5acdad-3c5c-4a99-9eca-2cfd37a372f9",
   "metadata": {},
   "source": [
    "### Средство сортировки данных\n",
    "Определим класс сортировки данных и создадим экземпляр класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73027e51-2911-4337-ae27-b5cff23824ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(\n",
    "        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [\n",
    "            {\"input_features\": feature[\"input_features\"][0]} for feature in features\n",
    "        ]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(\n",
    "            labels_batch.attention_mask.ne(1), -100\n",
    "        )\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52af8e47-58f2-4f94-9b82-b1271368a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc77056b-8c7d-4096-9a00-fbb994ebed21",
   "metadata": {},
   "source": [
    "### Функция оценки качества модели\n",
    "\n",
    "Определим функцию подсчета WER. Создадим нормалайзер текста - он используется для предотвращения ситуаций, когда, например `Кот` и `кот` считаются неверным предсказанием из-за наличия заглавной буквы. \n",
    "\n",
    "\n",
    "Полная документация тут: https://kurianbenoy.github.io/whisper_normalizer/basic.html#basictextnormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23aa1dcf-787c-47df-97dd-75129f30e233",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load('wer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "413cddbf-f8a8-4337-aba7-16ff401910f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
    "\n",
    "normalizer = BasicTextNormalizer()\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # Заменим -100 на  pad_token_id\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    # Пропускаем токены во время подсчета метрики\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    # Также посчитаем метрику wer orthographic \n",
    "    wer_ortho = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    # Подсчет WER метрики \n",
    "    pred_str_norm = [normalizer(pred) for pred in pred_str]\n",
    "    label_str_norm = [normalizer(label) for label in label_str]\n",
    "    # Фильтрация шагов для подсчета ненулевых сэмплов:\n",
    "    pred_str_norm = [pred_str_norm[i] for i in range(len(pred_str_norm)) if len(label_str_norm[i]) > 0]\n",
    "    label_str_norm = [label_str_norm[i] for i in range(len(label_str_norm)) if len(label_str_norm[i]) > 0]\n",
    "\n",
    "    # Выражаем в %\n",
    "    wer = 100 * metric.compute(predictions=pred_str_norm, references=label_str_norm)\n",
    "\n",
    "    return {\"wer_ortho\": wer_ortho, \"wer\": wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184e2d6d-108f-406a-a9b7-9b29f7d1bf19",
   "metadata": {},
   "source": [
    "### Загрузка модели, настройка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcd0fd0c-d55e-4a70-83c7-2281996c0837",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05a00f79-0e15-46ad-8f4e-bcfae27bc1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# Выключаем кэш из-за несовместимости с градиентными чекпоинтами, включаем после \n",
    "model.config.use_cache = False\n",
    "model.generate = partial(model.generate, language=\"russian\", task=\"transcribe\", use_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1700728-30c1-417f-be0e-61cbd94ecad7",
   "metadata": {},
   "source": [
    "### Найстрока аргументов модели для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d02d6f7-056b-436a-8875-eadeec6cc02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-small-ru\", \n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=1e-5,\n",
    "    lr_scheduler_type=\"constant_with_warmup\",\n",
    "    warmup_steps=50,\n",
    "    max_steps=500, \n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    fp16_full_eval=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=16,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5daf09bb-996d-4a29-a4f5-2191b639774d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "# Создание тренера, передача параметров обучающей и тестовой выборки\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=train_processed,\n",
    "    eval_dataset=test_processed,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b8e74df-5fb7-4f84-87bc-eeadc5902721",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Denis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:694: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 4:47:01, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer Ortho</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.419700</td>\n",
       "      <td>0.416742</td>\n",
       "      <td>28.060459</td>\n",
       "      <td>28.059017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.7030358695983887, metrics={'train_runtime': 17232.1414, 'train_samples_per_second': 0.464, 'train_steps_per_second': 0.029, 'total_flos': 2.30868320256e+18, 'train_loss': 0.7030358695983887, 'epoch': 0.24764735017335315})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616b84f3-64d3-4ad9-be21-8f6669cad258",
   "metadata": {},
   "source": [
    "После длительного (5 часов) обучения, видим коэффициент $WER=$~$28.06\\%$, что сигнализирует о точности в $W_{\\text{accuracy}}=1-WER\\approx71.94\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dff044d-2fd2-497a-8aae-94d030f13b85",
   "metadata": {},
   "source": [
    "# Выводы:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dca7c4-e381-43d8-aaaf-e90d4435da08",
   "metadata": {},
   "source": [
    "| Точность | Предобученная модель | Дообученная модель |\n",
    "|:--------:|:--------:|:--------:|\n",
    "|  $W_{\\text{accuracy}}$   |  $\\approx38.2\\%$   |  $\\approx71.94\\%$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be160c7-265a-4c9a-b9e6-544273dd80d2",
   "metadata": {},
   "source": [
    "В результате обучения модели whisper удалось поднять точность модели с $\\approx38.2\\%$ до $\\approx71.94\\%$. Если учесть, что модель обучалась лишь на части выборки (4Гб из 2.4Тб), мы можем сделать мы можем сделать вывод, что увеличение размера датасета поднимет точность модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c55e879-2ec6-4061-a6df-ee5aee8c5e76",
   "metadata": {},
   "source": [
    "Распознавание речи сейчас активно применяется в лидирующих IT компаниях по всему миру, в том числе и российских корпорациях, таких как Yandex, Mail.ru и прочие. Это перспективное направление, однако для обучения моделей требуются большие массивы данных и хорошие вычислительные мощности, которые пока что недоступны обычным разработчикам"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd757522-558a-4963-a36d-0ce3b1cfa619",
   "metadata": {},
   "source": [
    "Компании VK, Telegram и Yandex уже используют данные модели для распознавания речи в аудиосообщениях и клавиатуре, в голосовых помощниках Алиса и Маруся, в Яндекс-браузере для перевода зарубежной речи налету"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64659175-b15d-4801-b150-c64a825824b2",
   "metadata": {},
   "source": [
    "В русскоязычном сегменте интернета достаточно проблематично найти размеченный датасет с русской речью, точно также проблематично найти информацию о работе с нейронными сетями на русском языке, особенно на тему распознавания речи. В связи с популяризацией нейронных сетей эта проблема решается сама собой."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
